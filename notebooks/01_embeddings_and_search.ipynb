{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üáÆüá≥ Marathi Dictionary RAG - Phase 1\n",
    "## Embeddings and Vector Search\n",
    "\n",
    "**What we'll do in this notebook:**\n",
    "1. Load the MahaSBERT model (the \"brain\" that understands Marathi)\n",
    "2. See how words become numbers (embeddings)\n",
    "3. Load your dictionary data\n",
    "4. Create embeddings for all entries\n",
    "5. Store them in ChromaDB\n",
    "6. Search and find words!\n",
    "\n",
    "Let's go! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Check Everything is Installed\n",
    "\n",
    "Run this cell first. If you see errors, go back to the terminal and run:\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check all our packages are installed\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# These should all work without errors\n",
    "import torch\n",
    "print(f\"‚úÖ PyTorch version: {torch.__version__}\")\n",
    "\n",
    "import sentence_transformers\n",
    "print(f\"‚úÖ Sentence Transformers version: {sentence_transformers.__version__}\")\n",
    "\n",
    "import chromadb\n",
    "print(f\"‚úÖ ChromaDB version: {chromadb.__version__}\")\n",
    "\n",
    "import json\n",
    "print(f\"‚úÖ JSON module ready\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "print(f\"‚úÖ TQDM (progress bars) ready\")\n",
    "\n",
    "print(\"\\nüéâ Everything is installed! Let's continue.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Load MahaSBERT Model\n",
    "\n",
    "### What's happening here?\n",
    "\n",
    "MahaSBERT is like a translator that converts words into numbers. It was trained on millions of Marathi sentences, so it \"understands\" Marathi.\n",
    "\n",
    "**First time running this?** It will download the model (~400MB). This only happens once - after that, it's saved on your computer.\n",
    "\n",
    "‚òï This might take 1-2 minutes the first time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# This is the magic line - loading the Marathi-understanding model\n",
    "print(\"Loading MahaSBERT model... (this takes a minute the first time)\")\n",
    "\n",
    "model = SentenceTransformer('l3cube-pune/marathi-sentence-similarity-sbert')\n",
    "\n",
    "print(\"‚úÖ Model loaded!\")\n",
    "print(f\"   Model creates vectors with {model.get_sentence_embedding_dimension()} dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: See How Embeddings Work\n",
    "\n",
    "Let's turn some Marathi words into numbers and see what happens!\n",
    "\n",
    "### The Big Idea:\n",
    "- Similar words ‚Üí Similar numbers\n",
    "- Different words ‚Üí Different numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's embed a single word\n",
    "word = \"‡§™‡§æ‡§£‡•Ä\"\n",
    "\n",
    "# Turn it into numbers!\n",
    "embedding = model.encode(word)\n",
    "\n",
    "print(f\"Word: {word}\")\n",
    "print(f\"Embedding shape: {embedding.shape}\")  # Should be (768,)\n",
    "print(f\"\\nFirst 10 numbers: {embedding[:10]}\")\n",
    "print(f\"\\nThis word is now represented by {len(embedding)} numbers!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's compare similar vs different words\n",
    "# We'll use \"cosine similarity\" - a score from -1 to 1\n",
    "# 1 = identical, 0 = unrelated, -1 = opposite\n",
    "\n",
    "from sentence_transformers import util\n",
    "\n",
    "# Water-related words (should be similar)\n",
    "water_words = [\"‡§™‡§æ‡§£‡•Ä\", \"‡§ú‡§≤\", \"‡§™‡§æ‡§ä‡§∏\", \"‡§®‡§¶‡•Ä\"]\n",
    "\n",
    "# Unrelated word\n",
    "unrelated = \"‡§Æ‡§æ‡§Ç‡§ú‡§∞\"  # cat\n",
    "\n",
    "# Get embeddings for all\n",
    "water_embeddings = model.encode(water_words)\n",
    "cat_embedding = model.encode(unrelated)\n",
    "\n",
    "print(\"üåä Comparing water-related words to '‡§™‡§æ‡§£‡•Ä' (water):\\n\")\n",
    "\n",
    "pani_embedding = water_embeddings[0]  # ‡§™‡§æ‡§£‡•Ä\n",
    "\n",
    "for i, word in enumerate(water_words):\n",
    "    similarity = util.cos_sim(pani_embedding, water_embeddings[i]).item()\n",
    "    bar = \"‚ñà\" * int(similarity * 20)\n",
    "    print(f\"  ‡§™‡§æ‡§£‡•Ä ‚Üî {word:8} : {similarity:.3f} {bar}\")\n",
    "\n",
    "print(\"\\nüê± Comparing to unrelated word '‡§Æ‡§æ‡§Ç‡§ú‡§∞' (cat):\\n\")\n",
    "similarity = util.cos_sim(pani_embedding, cat_embedding).item()\n",
    "bar = \"‚ñà\" * int(similarity * 20)\n",
    "print(f\"  ‡§™‡§æ‡§£‡•Ä ‚Üî ‡§Æ‡§æ‡§Ç‡§ú‡§∞   : {similarity:.3f} {bar}\")\n",
    "\n",
    "print(\"\\nüëÜ See how water words have HIGH similarity (close to 1.0)?\")\n",
    "print(\"   But 'cat' has LOWER similarity? That's embeddings working!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Load Your Dictionary\n",
    "\n",
    "Now let's load the Berntsen dictionary you processed.\n",
    "\n",
    "**Make sure** you've copied `berntsen_dictionary_processed.json` to the `data/` folder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the dictionary\n",
    "data_path = Path(\"../data/berntsen_dictionary_processed.json\")\n",
    "\n",
    "# Check if file exists\n",
    "if not data_path.exists():\n",
    "    print(f\"‚ùå File not found at: {data_path.absolute()}\")\n",
    "    print(\"\\nüìÅ Please copy your berntsen_dictionary_processed.json to the data/ folder\")\n",
    "else:\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        dictionary = json.load(f)\n",
    "    \n",
    "    print(f\"‚úÖ Loaded dictionary with {len(dictionary):,} entries!\")\n",
    "    print(f\"\\nüìñ First entry looks like this:\\n\")\n",
    "    print(json.dumps(dictionary[0], indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what kinds of entries we have\n",
    "entry_types = {}\n",
    "for entry in dictionary:\n",
    "    t = entry.get('entry_type', 'unknown')\n",
    "    entry_types[t] = entry_types.get(t, 0) + 1\n",
    "\n",
    "print(\"üìä Entry types in your dictionary:\\n\")\n",
    "for entry_type, count in entry_types.items():\n",
    "    print(f\"   {entry_type}: {count:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Create Embeddings for ALL Entries\n",
    "\n",
    "Now the real work! We'll:\n",
    "1. Take each dictionary entry\n",
    "2. Use the `search_text` field (which has Devanagari + romanized + definitions)\n",
    "3. Turn it into an embedding\n",
    "\n",
    "**This will take a few minutes** for 5,000 entries. You'll see a progress bar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# We'll embed the 'search_text' field - it contains the most useful info\n",
    "# Let's first check a few examples\n",
    "\n",
    "print(\"üìù Examples of 'search_text' we'll embed:\\n\")\n",
    "for entry in dictionary[:3]:\n",
    "    print(f\"  ‚Ä¢ {entry['search_text'][:80]}...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's create ALL embeddings\n",
    "# We'll process in batches for efficiency\n",
    "\n",
    "print(\"üîÑ Creating embeddings for all dictionary entries...\")\n",
    "print(\"   (This takes 2-5 minutes depending on your computer)\\n\")\n",
    "\n",
    "# Extract all search texts\n",
    "search_texts = [entry['search_text'] for entry in dictionary]\n",
    "\n",
    "# Create embeddings in batches (faster than one at a time)\n",
    "batch_size = 64  # Process 64 entries at a time\n",
    "\n",
    "all_embeddings = []\n",
    "\n",
    "for i in tqdm(range(0, len(search_texts), batch_size), desc=\"Embedding batches\"):\n",
    "    batch = search_texts[i:i + batch_size]\n",
    "    batch_embeddings = model.encode(batch, show_progress_bar=False)\n",
    "    all_embeddings.extend(batch_embeddings)\n",
    "\n",
    "print(f\"\\n‚úÖ Created {len(all_embeddings):,} embeddings!\")\n",
    "print(f\"   Each embedding has {len(all_embeddings[0])} dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Store in ChromaDB\n",
    "\n",
    "Now we'll put everything in ChromaDB - our vector database.\n",
    "\n",
    "Think of ChromaDB like a super-organized library where:\n",
    "- Each book (dictionary entry) has a location based on its meaning\n",
    "- We can instantly find books that are \"nearby\" (similar meaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "# Create a ChromaDB client that saves to disk\n",
    "# This means your database persists even after you close the notebook!\n",
    "\n",
    "chroma_path = \"../chroma_db\"\n",
    "\n",
    "client = chromadb.PersistentClient(path=chroma_path)\n",
    "\n",
    "print(f\"‚úÖ ChromaDB client created!\")\n",
    "print(f\"   Data will be saved to: {chroma_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create (or get) a collection for our dictionary\n",
    "# A \"collection\" is like a folder that holds related items\n",
    "\n",
    "# Delete existing collection if it exists (so we can start fresh)\n",
    "try:\n",
    "    client.delete_collection(name=\"berntsen_dictionary\")\n",
    "    print(\"üóëÔ∏è  Deleted existing collection to start fresh\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Create new collection\n",
    "collection = client.create_collection(\n",
    "    name=\"berntsen_dictionary\",\n",
    "    metadata={\"description\": \"Berntsen Marathi-English Dictionary\"}\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Created collection: 'berntsen_dictionary'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now add all entries to the collection\n",
    "# We'll include metadata so we can filter and display results nicely\n",
    "\n",
    "print(\"üì• Adding entries to ChromaDB...\\n\")\n",
    "\n",
    "# Prepare data for ChromaDB\n",
    "ids = []\n",
    "embeddings_list = []\n",
    "documents = []\n",
    "metadatas = []\n",
    "\n",
    "for i, entry in enumerate(tqdm(dictionary, desc=\"Preparing entries\")):\n",
    "    ids.append(entry['entry_id'])\n",
    "    embeddings_list.append(all_embeddings[i].tolist())  # Convert numpy to list\n",
    "    documents.append(entry['search_text'])\n",
    "    \n",
    "    # Metadata - extra info we want to store and filter by\n",
    "    metadata = {\n",
    "        'headword': entry['headword_devanagari'],\n",
    "        'romanized': entry.get('headword_romanized', ''),\n",
    "        'entry_type': entry['entry_type'],\n",
    "        'source_page': entry['source_page'],\n",
    "        'full_entry': entry['full_entry'],\n",
    "        'source': 'berntsen'  # Will be useful when we add more dictionaries!\n",
    "    }\n",
    "    \n",
    "    # Add part of speech if available\n",
    "    if entry.get('definitions') and len(entry['definitions']) > 0:\n",
    "        first_def = entry['definitions'][0]\n",
    "        if first_def.get('pos'):\n",
    "            metadata['pos'] = first_def['pos']\n",
    "        if first_def.get('gender'):\n",
    "            metadata['gender'] = first_def['gender']\n",
    "    \n",
    "    metadatas.append(metadata)\n",
    "\n",
    "print(f\"\\n‚úÖ Prepared {len(ids):,} entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add everything to ChromaDB\n",
    "# We'll do this in batches because ChromaDB has limits\n",
    "\n",
    "batch_size = 500  # ChromaDB works well with batches of 500\n",
    "\n",
    "print(\"üì• Uploading to ChromaDB...\\n\")\n",
    "\n",
    "for i in tqdm(range(0, len(ids), batch_size), desc=\"Uploading batches\"):\n",
    "    end_idx = min(i + batch_size, len(ids))\n",
    "    \n",
    "    collection.add(\n",
    "        ids=ids[i:end_idx],\n",
    "        embeddings=embeddings_list[i:end_idx],\n",
    "        documents=documents[i:end_idx],\n",
    "        metadatas=metadatas[i:end_idx]\n",
    "    )\n",
    "\n",
    "print(f\"\\n‚úÖ Successfully added {collection.count():,} entries to ChromaDB!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 7: Let's Search! üîç\n",
    "\n",
    "The exciting part! Let's test our system.\n",
    "\n",
    "We'll:\n",
    "1. Take a Marathi word\n",
    "2. Convert it to an embedding\n",
    "3. Find similar entries in ChromaDB\n",
    "4. Display the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_dictionary(query, n_results=5):\n",
    "    \"\"\"\n",
    "    Search the dictionary for entries similar to the query.\n",
    "    \n",
    "    Args:\n",
    "        query: A Marathi word or phrase to search for\n",
    "        n_results: How many results to return (default 5)\n",
    "    \n",
    "    Returns:\n",
    "        Results from ChromaDB with entries and similarity scores\n",
    "    \"\"\"\n",
    "    # Step 1: Convert query to embedding\n",
    "    query_embedding = model.encode(query).tolist()\n",
    "    \n",
    "    # Step 2: Search ChromaDB\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=n_results,\n",
    "        include=['documents', 'metadatas', 'distances']\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def display_results(query, results):\n",
    "    \"\"\"\n",
    "    Display search results in a nice format.\n",
    "    \"\"\"\n",
    "    print(f\"\\nüîç Search: '{query}'\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if not results['ids'][0]:\n",
    "        print(\"No results found.\")\n",
    "        return\n",
    "    \n",
    "    for i, (id, metadata, distance) in enumerate(zip(\n",
    "        results['ids'][0],\n",
    "        results['metadatas'][0],\n",
    "        results['distances'][0]\n",
    "    )):\n",
    "        # Convert distance to similarity (lower distance = higher similarity)\n",
    "        # ChromaDB uses L2 distance by default\n",
    "        similarity = 1 / (1 + distance)  # Simple conversion to 0-1 range\n",
    "        \n",
    "        print(f\"\\n{i+1}. {metadata['headword']}\")\n",
    "        if metadata.get('romanized'):\n",
    "            print(f\"   ({metadata['romanized']})\")\n",
    "        print(f\"   üìñ {metadata['full_entry']}\")\n",
    "        print(f\"   üìä Match score: {similarity:.2%}\")\n",
    "        print(f\"   üìÑ Source: {metadata['source']}, page {metadata['source_page']}\")\n",
    "\n",
    "print(\"‚úÖ Search functions ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST 1: Simple word lookup\n",
    "query = \"‡§™‡§æ‡§£‡•Ä\"\n",
    "results = search_dictionary(query)\n",
    "display_results(query, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST 2: Semantic search - find related words!\n",
    "query = \"water\"  # English query - will it find Marathi water words?\n",
    "results = search_dictionary(query)\n",
    "display_results(query, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST 3: Try a concept\n",
    "query = \"‡§ñ‡§æ‡§£‡•á\"  # eating\n",
    "results = search_dictionary(query)\n",
    "display_results(query, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST 4: Your turn! Try any word\n",
    "query = \"‡§Ü‡§à\"  # mother - change this to anything!\n",
    "results = search_dictionary(query)\n",
    "display_results(query, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéâ Phase 1 Complete!\n",
    "\n",
    "### What you built:\n",
    "1. ‚úÖ Loaded MahaSBERT - a model that understands Marathi\n",
    "2. ‚úÖ Created embeddings for 5,000+ dictionary entries\n",
    "3. ‚úÖ Stored everything in ChromaDB (saved to disk!)\n",
    "4. ‚úÖ Built a working search function\n",
    "\n",
    "### What's saved:\n",
    "- Your ChromaDB database is saved in the `chroma_db/` folder\n",
    "- You can close this notebook and the data persists!\n",
    "\n",
    "### What's next (Phase 2):\n",
    "- Add an LLM (Claude Haiku) to make responses smarter\n",
    "- Handle morphology (‡§™‡§æ‡§£‡•ç‡§Ø‡§æ‡§≤‡§æ ‚Üí ‡§™‡§æ‡§£‡•Ä)\n",
    "- Better formatting of results\n",
    "\n",
    "---\n",
    "\n",
    "## Bonus: Interactive Search Cell\n",
    "\n",
    "Run this cell and type any word to search!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive search - run this and enter words!\n",
    "while True:\n",
    "    query = input(\"\\nüîç Enter a Marathi word (or 'quit' to exit): \")\n",
    "    if query.lower() == 'quit':\n",
    "        print(\"üëã Goodbye!\")\n",
    "        break\n",
    "    results = search_dictionary(query)\n",
    "    display_results(query, results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

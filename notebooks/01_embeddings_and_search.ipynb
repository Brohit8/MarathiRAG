{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üáÆüá≥ Marathi Dictionary RAG - Phase 1\n",
    "## Embeddings and Vector Search\n",
    "\n",
    "**What we'll do in this notebook:**\n",
    "1. Load the MahaSBERT model (the \"brain\" that understands Marathi)\n",
    "2. See how words become numbers (embeddings)\n",
    "3. Load your dictionary data\n",
    "4. Create embeddings for all entries\n",
    "5. Store them in ChromaDB\n",
    "6. Search and find words!\n",
    "\n",
    "Let's go! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Check Everything is Installed\n",
    "\n",
    "Run this cell first. If you see errors, go back to the terminal and run:\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.12.4 (main, Jun  6 2024, 18:26:44) [Clang 15.0.0 (clang-1500.1.0.2.5)]\n",
      "‚úÖ PyTorch version: 2.9.1\n",
      "‚úÖ Sentence Transformers version: 5.2.0\n",
      "‚úÖ ChromaDB version: 1.4.0\n",
      "‚úÖ JSON module ready\n",
      "‚úÖ TQDM (progress bars) ready\n",
      "\n",
      "üéâ Everything is installed! Let's continue.\n"
     ]
    }
   ],
   "source": [
    "# Let's check all our packages are installed\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# These should all work without errors\n",
    "import torch\n",
    "print(f\"‚úÖ PyTorch version: {torch.__version__}\")\n",
    "\n",
    "import sentence_transformers\n",
    "print(f\"‚úÖ Sentence Transformers version: {sentence_transformers.__version__}\")\n",
    "\n",
    "import chromadb\n",
    "print(f\"‚úÖ ChromaDB version: {chromadb.__version__}\")\n",
    "\n",
    "import json\n",
    "print(f\"‚úÖ JSON module ready\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "print(f\"‚úÖ TQDM (progress bars) ready\")\n",
    "\n",
    "print(\"\\nüéâ Everything is installed! Let's continue.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Load MahaSBERT Model\n",
    "\n",
    "### What's happening here?\n",
    "\n",
    "MahaSBERT is like a translator that converts words into numbers. It was trained on millions of Marathi sentences, so it \"understands\" Marathi.\n",
    "\n",
    "**First time running this?** It will download the model (~400MB). This only happens once - after that, it's saved on your computer.\n",
    "\n",
    "‚òï This might take 1-2 minutes the first time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MahaSBERT model... (this takes a minute the first time)\n",
      "‚úÖ Model loaded!\n",
      "   Model creates vectors with 768 dimensions\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# This is the magic line - loading the Marathi-understanding model\n",
    "print(\"Loading MahaSBERT model... (this takes a minute the first time)\")\n",
    "\n",
    "model = SentenceTransformer('l3cube-pune/marathi-sentence-similarity-sbert')\n",
    "\n",
    "print(\"‚úÖ Model loaded!\")\n",
    "print(f\"   Model creates vectors with {model.get_sentence_embedding_dimension()} dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: See How Embeddings Work\n",
    "\n",
    "Let's turn some Marathi words into numbers and see what happens!\n",
    "\n",
    "### The Big Idea:\n",
    "- Similar words ‚Üí Similar numbers\n",
    "- Different words ‚Üí Different numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: ‡§™‡§æ‡§£‡•Ä\n",
      "Embedding shape: (768,)\n",
      "\n",
      "First 10 numbers: [ 1.7880186e-02 -2.0560540e-02 -1.0075445e-03  1.7184960e-02\n",
      "  1.2032884e-02  1.1198540e-02 -2.0179005e-02  7.5856689e-05\n",
      " -2.7883681e-02 -1.3770126e-02]\n",
      "\n",
      "This word is now represented by 768 numbers!\n"
     ]
    }
   ],
   "source": [
    "# Let's embed a single word\n",
    "word = \"‡§™‡§æ‡§£‡•Ä\"\n",
    "\n",
    "# Turn it into numbers!\n",
    "embedding = model.encode(word)\n",
    "\n",
    "print(f\"Word: {word}\")\n",
    "print(f\"Embedding shape: {embedding.shape}\")  # Should be (768,)\n",
    "print(f\"\\nFirst 10 numbers: {embedding[:10]}\")\n",
    "print(f\"\\nThis word is now represented by {len(embedding)} numbers!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåä Comparing water-related words to '‡§™‡§æ‡§£‡•Ä' (water):\n",
      "\n",
      "  ‡§™‡§æ‡§£‡•Ä ‚Üî ‡§™‡§æ‡§£‡•Ä     : 1.000 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  ‡§™‡§æ‡§£‡•Ä ‚Üî ‡§ú‡§≤       : 0.850 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  ‡§™‡§æ‡§£‡•Ä ‚Üî ‡§™‡§æ‡§ä‡§∏     : 0.343 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  ‡§™‡§æ‡§£‡•Ä ‚Üî ‡§®‡§¶‡•Ä      : 0.521 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "üê± Comparing to unrelated word '‡§Æ‡§æ‡§Ç‡§ú‡§∞' (cat):\n",
      "\n",
      "  ‡§™‡§æ‡§£‡•Ä ‚Üî ‡§Æ‡§æ‡§Ç‡§ú‡§∞   : 0.173 ‚ñà‚ñà‚ñà\n",
      "\n",
      "üëÜ See how water words have HIGH similarity (close to 1.0)?\n",
      "   But 'cat' has LOWER similarity? That's embeddings working!\n"
     ]
    }
   ],
   "source": [
    "# Now let's compare similar vs different words\n",
    "# We'll use \"cosine similarity\" - a score from -1 to 1\n",
    "# 1 = identical, 0 = unrelated, -1 = opposite\n",
    "\n",
    "from sentence_transformers import util\n",
    "\n",
    "# Water-related words (should be similar)\n",
    "water_words = [\"‡§™‡§æ‡§£‡•Ä\", \"‡§ú‡§≤\", \"‡§™‡§æ‡§ä‡§∏\", \"‡§®‡§¶‡•Ä\"]\n",
    "\n",
    "# Unrelated word\n",
    "unrelated = \"‡§Æ‡§æ‡§Ç‡§ú‡§∞\"  # cat\n",
    "\n",
    "# Get embeddings for all\n",
    "water_embeddings = model.encode(water_words)\n",
    "cat_embedding = model.encode(unrelated)\n",
    "\n",
    "print(\"üåä Comparing water-related words to '‡§™‡§æ‡§£‡•Ä' (water):\\n\")\n",
    "\n",
    "pani_embedding = water_embeddings[0]  # ‡§™‡§æ‡§£‡•Ä\n",
    "\n",
    "for i, word in enumerate(water_words):\n",
    "    similarity = util.cos_sim(pani_embedding, water_embeddings[i]).item()\n",
    "    bar = \"‚ñà\" * int(similarity * 20)\n",
    "    print(f\"  ‡§™‡§æ‡§£‡•Ä ‚Üî {word:8} : {similarity:.3f} {bar}\")\n",
    "\n",
    "print(\"\\nüê± Comparing to unrelated word '‡§Æ‡§æ‡§Ç‡§ú‡§∞' (cat):\\n\")\n",
    "similarity = util.cos_sim(pani_embedding, cat_embedding).item()\n",
    "bar = \"‚ñà\" * int(similarity * 20)\n",
    "print(f\"  ‡§™‡§æ‡§£‡•Ä ‚Üî ‡§Æ‡§æ‡§Ç‡§ú‡§∞   : {similarity:.3f} {bar}\")\n",
    "\n",
    "print(\"\\nüëÜ See how water words have HIGH similarity (close to 1.0)?\")\n",
    "print(\"   But 'cat' has LOWER similarity? That's embeddings working!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Load Your Dictionary\n",
    "\n",
    "Now let's load the Berntsen dictionary you processed.\n",
    "\n",
    "**Make sure** you've copied `berntsen_dictionary_processed.json` to the `data/` folder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded dictionary with 10,460 entries!\n",
      "\n",
      "üìñ First entry looks like this:\n",
      "\n",
      "{\n",
      "  \"entry_id\": \"berntsen_‡§Ö_1\",\n",
      "  \"headword_devanagari\": \"‡§Ö\",\n",
      "  \"headword_romanized\": \"a\",\n",
      "  \"full_entry\": \"‡§Ö a pref. negative.\",\n",
      "  \"source_page\": 1,\n",
      "  \"entry_type\": \"headword\",\n",
      "  \"base_word\": null,\n",
      "  \"search_text\": \"‡§Ö a headword negative prefix\",\n",
      "  \"definitions\": [\n",
      "    {\n",
      "      \"definition\": \"negative\",\n",
      "      \"pos_display\": \"pref.\",\n",
      "      \"number\": null,\n",
      "      \"pos\": \"prefix\",\n",
      "      \"gender\": null,\n",
      "      \"declension_class\": null,\n",
      "      \"referenced_entry\": null\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the dictionary\n",
    "data_path = Path(\"../data/berntsen_dictionary_processed.json\")\n",
    "\n",
    "# Check if file exists\n",
    "if not data_path.exists():\n",
    "    print(f\"‚ùå File not found at: {data_path.absolute()}\")\n",
    "    print(\"\\nüìÅ Please copy your berntsen_dictionary_processed.json to the data/ folder\")\n",
    "else:\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        dictionary = json.load(f)\n",
    "    \n",
    "    print(f\"‚úÖ Loaded dictionary with {len(dictionary):,} entries!\")\n",
    "    print(f\"\\nüìñ First entry looks like this:\\n\")\n",
    "    print(json.dumps(dictionary[0], indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Entry types in your dictionary:\n",
      "\n",
      "   headword: 9,836\n",
      "   collocation: 624\n"
     ]
    }
   ],
   "source": [
    "# Let's see what kinds of entries we have\n",
    "entry_types = {}\n",
    "for entry in dictionary:\n",
    "    t = entry.get('entry_type', 'unknown')\n",
    "    entry_types[t] = entry_types.get(t, 0) + 1\n",
    "\n",
    "print(\"üìä Entry types in your dictionary:\\n\")\n",
    "for entry_type, count in entry_types.items():\n",
    "    print(f\"   {entry_type}: {count:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Create Embeddings for ALL Entries\n",
    "\n",
    "Now the real work! We'll:\n",
    "1. Take each dictionary entry\n",
    "2. Use the `search_text` field (which has Devanagari + romanized + definitions)\n",
    "3. Turn it into an embedding\n",
    "\n",
    "**This will take a few minutes** for 5,000 entries. You'll see a progress bar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Examples of 'search_text' we'll embed:\n",
      "\n",
      "  ‚Ä¢ ‡§Ö a headword negative prefix...\n",
      "\n",
      "  ‚Ä¢ ‡§Ö‡§Ç‡§ï a·πÖka headword number noun.masculine masculine issue (of a magazine, newspape...\n",
      "\n",
      "  ‚Ä¢ ‡§Ö‡§Ç‡§ï‡§ó‡§£‡§ø‡§§ a·πÖkaga·πáita headword arithmetic noun.neuter neuter...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# We'll embed the 'search_text' field - it contains the most useful info\n",
    "# Let's first check a few examples\n",
    "\n",
    "print(\"üìù Examples of 'search_text' we'll embed:\\n\")\n",
    "for entry in dictionary[:3]:\n",
    "    print(f\"  ‚Ä¢ {entry['search_text'][:80]}...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Creating embeddings for all dictionary entries...\n",
      "   (This takes 2-5 minutes depending on your computer)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 164/164 [02:01<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Created 10,460 embeddings!\n",
      "   Each embedding has 768 dimensions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Now let's create ALL embeddings\n",
    "# We'll process in batches for efficiency\n",
    "\n",
    "print(\"üîÑ Creating embeddings for all dictionary entries...\")\n",
    "print(\"   (This takes 2-5 minutes depending on your computer)\\n\")\n",
    "\n",
    "# Extract all search texts\n",
    "search_texts = [entry['search_text'] for entry in dictionary]\n",
    "\n",
    "# Create embeddings in batches (faster than one at a time)\n",
    "batch_size = 64  # Process 64 entries at a time\n",
    "\n",
    "all_embeddings = []\n",
    "\n",
    "for i in tqdm(range(0, len(search_texts), batch_size), desc=\"Embedding batches\"):\n",
    "    batch = search_texts[i:i + batch_size]\n",
    "    batch_embeddings = model.encode(batch, show_progress_bar=False)\n",
    "    all_embeddings.extend(batch_embeddings)\n",
    "\n",
    "print(f\"\\n‚úÖ Created {len(all_embeddings):,} embeddings!\")\n",
    "print(f\"   Each embedding has {len(all_embeddings[0])} dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Store in ChromaDB\n",
    "\n",
    "Now we'll put everything in ChromaDB - our vector database.\n",
    "\n",
    "Think of ChromaDB like a super-organized library where:\n",
    "- Each book (dictionary entry) has a location based on its meaning\n",
    "- We can instantly find books that are \"nearby\" (similar meaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ChromaDB client created!\n",
      "   Data will be saved to: ../chroma_db\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "# Create a ChromaDB client that saves to disk\n",
    "# This means your database persists even after you close the notebook!\n",
    "\n",
    "chroma_path = \"../chroma_db\"\n",
    "\n",
    "client = chromadb.PersistentClient(path=chroma_path)\n",
    "\n",
    "print(f\"‚úÖ ChromaDB client created!\")\n",
    "print(f\"   Data will be saved to: {chroma_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è  Deleted existing collection to start fresh\n",
      "‚úÖ Created collection: 'berntsen_dictionary'\n"
     ]
    }
   ],
   "source": [
    "# Create (or get) a collection for our dictionary\n",
    "# A \"collection\" is like a folder that holds related items\n",
    "\n",
    "# Delete existing collection if it exists (so we can start fresh)\n",
    "try:\n",
    "    client.delete_collection(name=\"berntsen_dictionary\")\n",
    "    print(\"üóëÔ∏è  Deleted existing collection to start fresh\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Create new collection\n",
    "collection = client.create_collection(\n",
    "    name=\"berntsen_dictionary\",\n",
    "    metadata={\"description\": \"Berntsen Marathi-English Dictionary\"}\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Created collection: 'berntsen_dictionary'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Adding entries to ChromaDB...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing entries: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10460/10460 [00:00<00:00, 62753.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Prepared 10,460 entries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Now add all entries to the collection\n",
    "# We'll include metadata so we can filter and display results nicely\n",
    "\n",
    "print(\"üì• Adding entries to ChromaDB...\\n\")\n",
    "\n",
    "# Prepare data for ChromaDB\n",
    "ids = []\n",
    "embeddings_list = []\n",
    "documents = []\n",
    "metadatas = []\n",
    "\n",
    "for i, entry in enumerate(tqdm(dictionary, desc=\"Preparing entries\")):\n",
    "    ids.append(entry['entry_id'])\n",
    "    embeddings_list.append(all_embeddings[i].tolist())  # Convert numpy to list\n",
    "    documents.append(entry['search_text'])\n",
    "    \n",
    "    # Metadata - extra info we want to store and filter by\n",
    "    # IMPORTANT: ChromaDB doesn't accept None values!\n",
    "    metadata = {\n",
    "        'headword': entry['headword_devanagari'],\n",
    "        'entry_type': entry['entry_type'],\n",
    "        'source': 'berntsen'  # Will be useful when we add more dictionaries!\n",
    "    }\n",
    "    \n",
    "    # Add all optional fields, filtering out None values\n",
    "    optional_fields = {\n",
    "        'romanized': entry.get('headword_romanized'),\n",
    "        'source_page': entry.get('source_page'),\n",
    "        'full_entry': entry.get('full_entry'),\n",
    "    }\n",
    "    \n",
    "    # Only add fields that have actual values (not None)\n",
    "    for key, value in optional_fields.items():\n",
    "        if value is not None:\n",
    "            metadata[key] = value\n",
    "    \n",
    "    # Add part of speech if available\n",
    "    if entry.get('definitions') and len(entry['definitions']) > 0:\n",
    "        first_def = entry['definitions'][0]\n",
    "        if first_def.get('pos'):\n",
    "            metadata['pos'] = first_def['pos']\n",
    "        if first_def.get('gender'):\n",
    "            metadata['gender'] = first_def['gender']\n",
    "    \n",
    "    metadatas.append(metadata)\n",
    "\n",
    "print(f\"\\n‚úÖ Prepared {len(ids):,} entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Uploading to ChromaDB...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21/21 [00:06<00:00,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Successfully added 10,460 entries to ChromaDB!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Add everything to ChromaDB\n",
    "# We'll do this in batches because ChromaDB has limits\n",
    "\n",
    "batch_size = 500  # ChromaDB works well with batches of 500\n",
    "\n",
    "print(\"üì• Uploading to ChromaDB...\\n\")\n",
    "\n",
    "for i in tqdm(range(0, len(ids), batch_size), desc=\"Uploading batches\"):\n",
    "    end_idx = min(i + batch_size, len(ids))\n",
    "    \n",
    "    collection.add(\n",
    "        ids=ids[i:end_idx],\n",
    "        embeddings=embeddings_list[i:end_idx],\n",
    "        documents=documents[i:end_idx],\n",
    "        metadatas=metadatas[i:end_idx]\n",
    "    )\n",
    "\n",
    "print(f\"\\n‚úÖ Successfully added {collection.count():,} entries to ChromaDB!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 7: Let's Search! üîç\n",
    "\n",
    "The exciting part! Let's test our system.\n",
    "\n",
    "We'll:\n",
    "1. Take a Marathi word\n",
    "2. Convert it to an embedding\n",
    "3. Find similar entries in ChromaDB\n",
    "4. Display the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Search functions ready!\n"
     ]
    }
   ],
   "source": [
    "def search_dictionary(query, n_results=5):\n",
    "    \"\"\"\n",
    "    Search the dictionary for entries similar to the query.\n",
    "    \n",
    "    Args:\n",
    "        query: A Marathi word or phrase to search for\n",
    "        n_results: How many results to return (default 5)\n",
    "    \n",
    "    Returns:\n",
    "        Results from ChromaDB with entries and similarity scores\n",
    "    \"\"\"\n",
    "    # Step 1: Convert query to embedding\n",
    "    query_embedding = model.encode(query).tolist()\n",
    "    \n",
    "    # Step 2: Search ChromaDB\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=n_results,\n",
    "        include=['documents', 'metadatas', 'distances']\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def display_results(query, results):\n",
    "    \"\"\"\n",
    "    Display search results in a nice format.\n",
    "    \"\"\"\n",
    "    print(f\"\\nüîç Search: '{query}'\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if not results['ids'][0]:\n",
    "        print(\"No results found.\")\n",
    "        return\n",
    "    \n",
    "    for i, (id, metadata, distance) in enumerate(zip(\n",
    "        results['ids'][0],\n",
    "        results['metadatas'][0],\n",
    "        results['distances'][0]\n",
    "    )):\n",
    "        # Convert distance to similarity (lower distance = higher similarity)\n",
    "        # ChromaDB uses L2 distance by default\n",
    "        similarity = 1 / (1 + distance)  # Simple conversion to 0-1 range\n",
    "        \n",
    "        print(f\"\\n{i+1}. {metadata['headword']}\")\n",
    "        if metadata.get('romanized'):\n",
    "            print(f\"   ({metadata['romanized']})\")\n",
    "        print(f\"   üìñ {metadata['full_entry']}\")\n",
    "        print(f\"   üìä Match score: {similarity:.2%}\")\n",
    "        print(f\"   üìÑ Source: {metadata['source']}, page {metadata['source_page']}\")\n",
    "\n",
    "print(\"‚úÖ Search functions ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Search: '‡§™‡§æ‡§£‡•Ä'\n",
      "============================================================\n",
      "\n",
      "1. ‡§™‡§æ‡§£‡•Ä relinquish. ‡§™‡§æ‡§£‡•ç‡§Ø‡§æ‡§§ ‡§™‡§π‡§æ‡§£‡•á\n",
      "   üìñ ‡§™‡§æ‡§£‡•Ä relinquish. ‡§™‡§æ‡§£‡•ç‡§Ø‡§æ‡§§ ‡§™‡§π‡§æ‡§£‡•á to hate\n",
      "   üìä Match score: 90.81%\n",
      "   üìÑ Source: berntsen, page 87\n",
      "\n",
      "2. ‡§ú‡§≤\n",
      "   (jala)\n",
      "   üìñ ‡§ú‡§≤ jala n. water.\n",
      "   üìä Match score: 90.34%\n",
      "   üìÑ Source: berntsen, page 49\n",
      "\n",
      "3. ‡§™‡§æ‡§£‡•Ä ‡§∏‡•ã‡§°‡§£‡•á to give up\n",
      "   üìñ ‡§™‡§æ‡§£‡•Ä ‡§∏‡•ã‡§°‡§£‡•á to give up to hate\n",
      "   üìä Match score: 89.97%\n",
      "   üìÑ Source: berntsen, page 87\n",
      "\n",
      "4. ‡§™‡§æ‡§£‡§ö‡§ï‡•ç‡§ï‡•Ä\n",
      "   (pƒÅ·πáacakkƒ´)\n",
      "   üìñ ‡§™‡§æ‡§£‡§ö‡§ï‡•ç‡§ï‡•Ä pƒÅ·πáacakkƒ´ f. water mill.\n",
      "   üìä Match score: 89.92%\n",
      "   üìÑ Source: berntsen, page 87\n",
      "\n",
      "5. ‡§™‡§æ‡§£‡•Ä ‡§™‡§°‡§£‡•á\n",
      "   üìñ ‡§™‡§æ‡§£‡•Ä ‡§™‡§°‡§£‡•á to be spoiled\n",
      "   üìä Match score: 89.14%\n",
      "   üìÑ Source: berntsen, page 87\n"
     ]
    }
   ],
   "source": [
    "# TEST 1: Simple word lookup\n",
    "query = \"‡§™‡§æ‡§£‡•Ä\"\n",
    "results = search_dictionary(query)\n",
    "display_results(query, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Search: 'water'\n",
      "============================================================\n",
      "\n",
      "1. ‡§ú‡§≤\n",
      "   (jala)\n",
      "   üìñ ‡§ú‡§≤ jala n. water.\n",
      "   üìä Match score: 91.26%\n",
      "   üìÑ Source: berntsen, page 49\n",
      "\n",
      "2. ‡§™‡§æ‡§£‡•Ä relinquish. ‡§™‡§æ‡§£‡•ç‡§Ø‡§æ‡§§ ‡§™‡§π‡§æ‡§£‡•á\n",
      "   üìñ ‡§™‡§æ‡§£‡•Ä relinquish. ‡§™‡§æ‡§£‡•ç‡§Ø‡§æ‡§§ ‡§™‡§π‡§æ‡§£‡•á to hate\n",
      "   üìä Match score: 90.61%\n",
      "   üìÑ Source: berntsen, page 87\n",
      "\n",
      "3. ‡§™‡§æ‡§£‡•Ä ‡§∏‡•ã‡§°‡§£‡•á to give up\n",
      "   üìñ ‡§™‡§æ‡§£‡•Ä ‡§∏‡•ã‡§°‡§£‡•á to give up to hate\n",
      "   üìä Match score: 89.75%\n",
      "   üìÑ Source: berntsen, page 87\n",
      "\n",
      "4. ‡§™‡§æ‡§£‡§ö‡§ï‡•ç‡§ï‡•Ä\n",
      "   (pƒÅ·πáacakkƒ´)\n",
      "   üìñ ‡§™‡§æ‡§£‡§ö‡§ï‡•ç‡§ï‡•Ä pƒÅ·πáacakkƒ´ f. water mill.\n",
      "   üìä Match score: 89.56%\n",
      "   üìÑ Source: berntsen, page 87\n",
      "\n",
      "5. ‡§™‡§æ‡§£‡§µ‡§†‡§æ\n",
      "   (pƒÅ·πáava·π≠hƒÅ)\n",
      "   üìñ ‡§™‡§æ‡§£‡§µ‡§†‡§æ pƒÅ·πáava·π≠hƒÅ m. a place on the bank of a river or stream where people fill water, wash, etc.\n",
      "   üìä Match score: 89.30%\n",
      "   üìÑ Source: berntsen, page 87\n"
     ]
    }
   ],
   "source": [
    "# TEST 2: Semantic search - find related words!\n",
    "query = \"water\"  # English query - will it find Marathi water words?\n",
    "results = search_dictionary(query)\n",
    "display_results(query, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Search: '‡§ñ‡§æ‡§£‡•á'\n",
      "============================================================\n",
      "\n",
      "1. ‡§ñ‡§æ‡§ä ‡§ò‡§æ‡§≤‡§£‡•á\n",
      "   üìñ ‡§ñ‡§æ‡§ä ‡§ò‡§æ‡§≤‡§£‡•á to feed\n",
      "   üìä Match score: 88.62%\n",
      "   üìÑ Source: berntsen, page 31\n",
      "\n",
      "2. ‡§≠‡§ï‡•ç‡§∑‡§£\n",
      "   (bhak·π£a·πáa)\n",
      "   üìñ ‡§≠‡§ï‡•ç‡§∑‡§£ bhak·π£a·πáa n. eating.\n",
      "   üìä Match score: 88.09%\n",
      "   üìÑ Source: berntsen, page 109\n",
      "\n",
      "3. ‡§ñ‡§æ‡§ä\n",
      "   (khƒÅ≈´)\n",
      "   üìñ ‡§ñ‡§æ‡§ä khƒÅ≈´ m. snacks, `eats'. ‡•¶ ‡§ò‡§æ‡§≤‡§£‡•á to feed.\n",
      "   üìä Match score: 87.73%\n",
      "   üìÑ Source: berntsen, page 31\n",
      "\n",
      "4. ‡§ú‡•á‡§µ‡§£\n",
      "   (jƒìva·πáa)\n",
      "   üìñ ‡§ú‡•á‡§µ‡§£ jƒìva·πáa n. meal, food.\n",
      "   üìä Match score: 87.66%\n",
      "   üìÑ Source: berntsen, page 51\n",
      "\n",
      "5. ‡§Æ‡§ø‡§∑‡•ç‡§ü‡§æ‡§®‡•ç‡§®\n",
      "   (mi·π£·π≠ƒÅnna)\n",
      "   üìñ ‡§Æ‡§ø‡§∑‡•ç‡§ü‡§æ‡§®‡•ç‡§® mi·π£·π≠ƒÅnna n. good food.\n",
      "   üìä Match score: 87.31%\n",
      "   üìÑ Source: berntsen, page 119\n"
     ]
    }
   ],
   "source": [
    "# TEST 3: Try a concept\n",
    "query = \"‡§ñ‡§æ‡§£‡•á\"  # eating\n",
    "results = search_dictionary(query)\n",
    "display_results(query, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Search: '‡§∞‡•ã‡§ü‡•Ä'\n",
      "============================================================\n",
      "\n",
      "1. ‡§∞‡•ã‡§ü‡•Ä\n",
      "   (r≈ç·π≠ƒ´)\n",
      "   üìñ ‡§∞‡•ã‡§ü‡•Ä r≈ç·π≠ƒ´ f. bread.\n",
      "   üìä Match score: 90.49%\n",
      "   üìÑ Source: berntsen, page 128\n",
      "\n",
      "2. ‡§∞‡•ã‡§ü\n",
      "   (r≈ç·π≠a)\n",
      "   üìñ ‡§∞‡•ã‡§ü r≈ç·π≠a m. thick bread.\n",
      "   üìä Match score: 86.64%\n",
      "   üìÑ Source: berntsen, page 128\n",
      "\n",
      "3. ‡§ö‡§™‡§æ‡§§‡•Ä\n",
      "   (capƒÅtƒ´)\n",
      "   üìñ ‡§ö‡§™‡§æ‡§§‡•Ä capƒÅtƒ´ f. wheat pancake used as bread. See ‡§™‡•ã‡§≥‡•Ä .\n",
      "   üìä Match score: 85.75%\n",
      "   üìÑ Source: berntsen, page 42\n",
      "\n",
      "4. ‡§®‡§ø‡§§‡§ï‡•ã‡§∞\n",
      "   (nitak≈çra)\n",
      "   üìñ ‡§®‡§ø‡§§‡§ï‡•ã‡§∞ nitak≈çra adj. inv. one eighth of a round object like a ‡§≠‡§æ‡§ï‡§∞‡•Ä .\n",
      "   üìä Match score: 85.38%\n",
      "   üìÑ Source: berntsen, page 78\n",
      "\n",
      "5. ‡§™‡•ã‡§≥‡•Ä\n",
      "   (p≈ç·∏∑ƒ´)\n",
      "   üìñ ‡§™‡•ã‡§≥‡•Ä p≈ç·∏∑ƒ´ f. 1. flat bread of wheat flour. 2. dewlap.\n",
      "   üìä Match score: 85.10%\n",
      "   üìÑ Source: berntsen, page 94\n"
     ]
    }
   ],
   "source": [
    "# TEST 4: Your turn! Try any word\n",
    "query = \"‡§∞‡•ã‡§ü‡•Ä\"  # mother - change this to anything!\n",
    "results = search_dictionary(query)\n",
    "display_results(query, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéâ Phase 1 Complete!\n",
    "\n",
    "### What you built:\n",
    "1. ‚úÖ Loaded MahaSBERT - a model that understands Marathi\n",
    "2. ‚úÖ Created embeddings for 5,000+ dictionary entries\n",
    "3. ‚úÖ Stored everything in ChromaDB (saved to disk!)\n",
    "4. ‚úÖ Built a working search function\n",
    "\n",
    "### What's saved:\n",
    "- Your ChromaDB database is saved in the `chroma_db/` folder\n",
    "- You can close this notebook and the data persists!\n",
    "\n",
    "### What's next (Phase 2):\n",
    "- Add an LLM (Claude Haiku) to make responses smarter\n",
    "- Handle morphology (‡§™‡§æ‡§£‡•ç‡§Ø‡§æ‡§≤‡§æ ‚Üí ‡§™‡§æ‡§£‡•Ä)\n",
    "- Better formatting of results\n",
    "\n",
    "---\n",
    "\n",
    "## Bonus: Interactive Search Cell\n",
    "\n",
    "Run this cell and type any word to search!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Search: '‡§™‡§æ‡§®‡§∏‡•á'\n",
      "============================================================\n",
      "\n",
      "1. ‡§™‡§ø‡§ï‡§≤‡•á\n",
      "   (pikalƒì)\n",
      "   üìñ ‡§™‡§ø‡§ï‡§≤‡•á pikalƒì , ‡§™‡§æ‡§® pƒÅna an extremely old person.\n",
      "   üìä Match score: 86.51%\n",
      "   üìÑ Source: berntsen, page 89\n",
      "\n",
      "2. ‡§™‡§æ‡§®‡§∏‡•Å‡§™‡§æ‡§∞‡•Ä\n",
      "   (pƒÅnasupƒÅrƒ´)\n",
      "   üìñ ‡§™‡§æ‡§®‡§∏‡•Å‡§™‡§æ‡§∞‡•Ä pƒÅnasupƒÅrƒ´ f. 1. betel leaf and betel nut. 2. reception.\n",
      "   üìä Match score: 86.09%\n",
      "   üìÑ Source: berntsen, page 87\n",
      "\n",
      "3. ‡§™‡§æ‡§®‡§æ\n",
      "   (pƒÅnƒÅ)\n",
      "   üìñ ‡§™‡§æ‡§®‡§æ pƒÅnƒÅ m. spanner, wrench.\n",
      "   üìä Match score: 85.48%\n",
      "   üìÑ Source: berntsen, page 87\n",
      "\n",
      "4. ‡§™‡§æ‡§≤‡•Å‡§™‡§¶\n",
      "   (pƒÅlupada)\n",
      "   üìñ ‡§™‡§æ‡§≤‡•Å‡§™‡§¶ pƒÅlupada n. refrain.\n",
      "   üìä Match score: 84.90%\n",
      "   üìÑ Source: berntsen, page 89\n",
      "\n",
      "5. ‡§™‡•Ä‡§™\n",
      "   (pƒ´pa)\n",
      "   üìñ ‡§™‡•Ä‡§™ pƒ´pa n. cask, barrel.\n",
      "   üìä Match score: 84.85%\n",
      "   üìÑ Source: berntsen, page 90\n",
      "\n",
      "üîç Search: ''\n",
      "============================================================\n",
      "\n",
      "1. ‡§ö‡§ï‡§æ‡§ü‡•ç‡§Ø\n",
      "   (cakƒÅ·π≠ya)\n",
      "   üìñ ‡§ö‡§ï‡§æ‡§ü‡•ç‡§Ø cakƒÅ·π≠ya f.pl. idle talk. ‡•¶ ‡§™‡•¢‡§ü‡§£‡•á to chat idly.\n",
      "   üìä Match score: 79.66%\n",
      "   üìÑ Source: berntsen, page 41\n",
      "\n",
      "2. ‡§™‡§π‡§æ‡§∞‡§æ ‡§ï‡§∞‡§£‡•á\n",
      "   üìñ ‡§™‡§π‡§æ‡§∞‡§æ ‡§ï‡§∞‡§£‡•á to keep a watch, guard\n",
      "   üìä Match score: 79.63%\n",
      "   üìÑ Source: berntsen, page 85\n",
      "\n",
      "3. ‡§®‡§ø‡§∞‡•Ä‡§ï‡•ç‡§∑‡§£\n",
      "   (nirƒ´k·π£a·πáa)\n",
      "   üìñ ‡§®‡§ø‡§∞‡•Ä‡§ï‡•ç‡§∑‡§£ nirƒ´k·π£a·πáa n. observation.\n",
      "   üìä Match score: 79.34%\n",
      "   üìÑ Source: berntsen, page 79\n",
      "\n",
      "4. ‡§∏‡•Å‡§§‡§∞‡§æ‡§Æ\n",
      "   (sutarƒÅma)\n",
      "   üìñ ‡§∏‡•Å‡§§‡§∞‡§æ‡§Æ sutarƒÅma adv. never, not at all.\n",
      "   üìä Match score: 79.29%\n",
      "   üìÑ Source: berntsen, page 160\n",
      "\n",
      "5. ‡§®‡§ø‡§™‡§ü‡§£‡•á\n",
      "   (nipa·π≠a·πáƒì)\n",
      "   üìñ ‡§®‡§ø‡§™‡§ü‡§£‡•á nipa·π≠a·πáƒì v.t. to wipe clean.\n",
      "   üìä Match score: 79.29%\n",
      "   üìÑ Source: berntsen, page 78\n"
     ]
    }
   ],
   "source": [
    "# Interactive search - run this and enter words!\n",
    "while True:\n",
    "    query = input(\"\\nüîç Enter a Marathi word (or 'quit' to exit): \")\n",
    "    if query.lower() == 'quit':\n",
    "        print(\"üëã Goodbye!\")\n",
    "        break\n",
    "    results = search_dictionary(query)\n",
    "    display_results(query, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c51687e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo\n",
    "#1.Remove भोकणे and सुरुवात"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "54617efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9836 entries\n",
      "\n",
      "Processed 9836 entries\n",
      "\n",
      "Example entry (index 300):\n",
      "{\n",
      "  \"entry_id\": \"berntsen_अवलंबून_5\",\n",
      "  \"headword_devanagari\": \"अवलंबून\",\n",
      "  \"headword_romanized\": \"avalambūna\",\n",
      "  \"full_entry\": \"अवलंबून avalambūna , असणे asaṇē to be dependent on.\",\n",
      "  \"source_page\": 5,\n",
      "  \"entry_type\": \"headword\",\n",
      "  \"base_word\": null,\n",
      "  \"search_text\": null\n",
      "}\n",
      "\n",
      "Schema fields present:\n",
      "  - entry_id: ✓\n",
      "  - entry_type: headword\n",
      "  - base_word: None\n",
      "  - search_text: None\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CELL 1: Import and Schema Setup\n",
    "# ==============================================================================\n",
    "# This cell:\n",
    "# - Loads the raw dictionary JSON\n",
    "# - Creates the base schema for each entry\n",
    "# - Adds entry_id, entry_type, base_word, search_text fields\n",
    "# - Removes part_of_speech field\n",
    "# - definitions[] array is added in the next cell\n",
    "\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from copy import deepcopy\n",
    "\n",
    "# Load the dictionary\n",
    "with open('berntsen_dictionary.json', 'r', encoding='utf-8') as f:\n",
    "    original_data = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(original_data)} entries\")\n",
    "\n",
    "# Create new data with proper field ordering and complete schema\n",
    "data = []\n",
    "for entry in original_data:\n",
    "    new_entry = OrderedDict()\n",
    "    \n",
    "    # Core identification fields\n",
    "    new_entry['entry_id'] = f\"berntsen_{entry['headword_devanagari']}_{entry['source_page']}\"\n",
    "    new_entry['headword_devanagari'] = entry['headword_devanagari']\n",
    "    new_entry['headword_romanized'] = entry['headword_romanized']\n",
    "    new_entry['full_entry'] = entry['full_entry']\n",
    "    new_entry['source_page'] = entry['source_page']\n",
    "    \n",
    "    # Entry type: 'headword' for normal entries, 'collocation' for phrase entries\n",
    "    # All entries start as 'headword'; collocations are created separately later\n",
    "    new_entry['entry_type'] = 'headword'\n",
    "    \n",
    "    # definitions[] - populated in Cell 2 by parse_definitions()\n",
    "    # Each definition will have: definition, pos_display, number, pos, gender,\n",
    "    # declension_class, referenced_entry\n",
    "    \n",
    "    # base_word - only used for collocation entries, null for headwords\n",
    "    # Will contain: entry_id, headword_devanagari, headword_romanized, definition, pos\n",
    "    new_entry['base_word'] = None\n",
    "    \n",
    "    # search_text - computed at the end after all processing is complete\n",
    "    # Will concatenate all searchable fields for vector embedding\n",
    "    new_entry['search_text'] = None\n",
    "    \n",
    "    data.append(new_entry)\n",
    "\n",
    "# Verify the result\n",
    "print(f\"\\nProcessed {len(data)} entries\")\n",
    "print(\"\\nExample entry (index 300):\")\n",
    "print(json.dumps(data[300], ensure_ascii=False, indent=2))\n",
    "print(\"\\nSchema fields present:\")\n",
    "print(f\"  - entry_id: ✓\")\n",
    "print(f\"  - entry_type: {data[0]['entry_type']}\")\n",
    "print(f\"  - base_word: {data[0]['base_word']}\")\n",
    "print(f\"  - search_text: {data[0]['search_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a20484bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Berntsen Dictionary, how part of speech is represented\n",
    "# Pattern 1: Sequential POS sections (most common)\n",
    "#       form: headword romanized POS1 definition(s). POS2 definition(s).\n",
    "#       example: \"अति ati adv. too much. pref. extremely, too much, over-.\"\n",
    "#       description: Each POS gets its own definition section which is separated by periods\n",
    "# Pattern 2: Numbered definitions within same POS\n",
    "#       form: headword romanized POS 1. def1. 2. def2. 3. def3.\n",
    "#       example: \"अंक aṅka m. 1. number. 2. issue (of a magazine, newspaper). 3. act (of a play).\"\n",
    "#       description: Numbers belong to the SAME POS. All numbered definitions share the first POS mentioned\n",
    "# Pattern 3: Mixed - numbered defs THEN new POS\n",
    "#       form: headword romanized POS1 1. def1. 2. def2. POS2 def3.\n",
    "#       example: \"अखंड akhaṇḍa adj. inv. 1. entire, in one piece. 2. continuous. adv. continuously.\"\n",
    "#       explanation of example: Definitions 1 and 2 belong to adj. inv. \n",
    "#       When adv. appears, it starts a NEW section with its own definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ca1aa47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries: 9836\n",
      "Entries with definitions: 9836 (100.0%)\n",
      "Entries without definitions: 0 (0.0%)\n",
      "Entries with null POS: 348 (3.5%)\n",
      "Total definitions parsed: 12167\n",
      "Average definitions per entry: 1.24\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CELL 2: Parse Definitions\n",
    "# ==============================================================================\n",
    "# This cell:\n",
    "# - Parses full_entry to extract individual definitions\n",
    "# - Identifies POS markers and numbered definitions\n",
    "# - Creates definitions[] array with full schema:\n",
    "#   definition, pos_display, number, pos, gender, declension_class, referenced_entry\n",
    "# - referenced_entry is initialized as None, populated in later cells\n",
    "\n",
    "import re\n",
    "\n",
    "def parse_definitions(entry):\n",
    "    \"\"\"\n",
    "    Parse the full_entry to extract definitions with their POS and numbers.\n",
    "    \n",
    "    Args:\n",
    "        entry: Dictionary containing 'full_entry', 'headword_romanized'\n",
    "    \n",
    "    Returns:\n",
    "        List of definition dictionaries with full schema\n",
    "    \"\"\"\n",
    "    full_entry = entry['full_entry']\n",
    "    romanized = entry['headword_romanized']\n",
    "    \n",
    "    # Step 1: Extract the definition part (everything after romanized headword)\n",
    "    parts = full_entry.split(romanized, 1)\n",
    "    if len(parts) <= 1:\n",
    "        return []\n",
    "    \n",
    "    definition_text = parts[1].strip()\n",
    "    \n",
    "    # If definition_text starts with comma, remove it\n",
    "    if definition_text.startswith(','):\n",
    "        definition_text = definition_text[1:].strip()\n",
    "    \n",
    "    if not definition_text:\n",
    "        return []\n",
    "    \n",
    "    # Step 2: Define all possible POS markers (order matters - longest first)\n",
    "    pos_markers = [\n",
    "        'adj. inv.', 'adv. suff.', 'adj. suff. inv.', 'adj. suff.',\n",
    "        'n. suff.', 'n.suff.', 'm. suff.', 'f. suff.', \n",
    "        'v. t.', 'v. i.', 'v.i.', 'v.t.',\n",
    "        'adj.', 'adv.', 'pref.', 'suff.',\n",
    "        'conj.', 'post.', 'pron.', 'interj.', 'poss.',\n",
    "        'f.(i)', 'f.(e)', 'm.(i)', 'm.(e)',\n",
    "        'n.', 'm.', 'f.'\n",
    "    ]\n",
    "    \n",
    "    # Step 3: Find all POS markers and their positions\n",
    "    pos_locations = []\n",
    "    for pos in pos_markers:\n",
    "        index = 0\n",
    "        while True:\n",
    "            index = definition_text.find(pos, index)\n",
    "            if index == -1:\n",
    "                break\n",
    "            if index == 0 or definition_text[index-1] in [' ', '.']:\n",
    "                end_index = index + len(pos)\n",
    "                if end_index >= len(definition_text) or definition_text[end_index] == ' ':\n",
    "                    pos_locations.append({\n",
    "                        'pos_display': pos,\n",
    "                        'start': index,\n",
    "                        'end': end_index\n",
    "                    })\n",
    "            index += 1\n",
    "    \n",
    "    pos_locations.sort(key=lambda x: x['start'])\n",
    "    \n",
    "    # Step 4: If no POS found, treat entire text as definition with null POS\n",
    "    if not pos_locations:\n",
    "        cleaned_text = definition_text.strip()\n",
    "        if cleaned_text.endswith('.'):\n",
    "            cleaned_text = cleaned_text[:-1].strip()\n",
    "        \n",
    "        if cleaned_text:\n",
    "            return [{\n",
    "                'definition': cleaned_text,\n",
    "                'pos_display': None,\n",
    "                'number': None,\n",
    "                'pos': None,\n",
    "                'gender': None,\n",
    "                'declension_class': None,\n",
    "                'referenced_entry': None\n",
    "            }]\n",
    "        else:\n",
    "            return []\n",
    "    \n",
    "    # Step 5: Split text into sections by POS\n",
    "    definitions = []\n",
    "    \n",
    "    for i, pos_info in enumerate(pos_locations):\n",
    "        current_pos = pos_info['pos_display']\n",
    "        start = pos_info['end']\n",
    "        \n",
    "        if i + 1 < len(pos_locations):\n",
    "            end = pos_locations[i + 1]['start']\n",
    "        else:\n",
    "            end = len(definition_text)\n",
    "        \n",
    "        section_text = definition_text[start:end].strip()\n",
    "        \n",
    "        # Step 6: Check if this section has numbered definitions\n",
    "        numbered_pattern = r'(\\d+)\\.\\s*([^0-9]+?)(?=\\s*\\d+\\.|$)'\n",
    "        numbered_matches = list(re.finditer(numbered_pattern, section_text))\n",
    "        \n",
    "        if numbered_matches:\n",
    "            for match in numbered_matches:\n",
    "                number = int(match.group(1))\n",
    "                def_text = match.group(2).strip()\n",
    "                \n",
    "                if def_text.endswith('.'):\n",
    "                    def_text = def_text[:-1].strip()\n",
    "                \n",
    "                if def_text:\n",
    "                    definitions.append({\n",
    "                        'definition': def_text,\n",
    "                        'pos_display': current_pos,\n",
    "                        'number': number,\n",
    "                        'pos': None,\n",
    "                        'gender': None,\n",
    "                        'declension_class': None,\n",
    "                        'referenced_entry': None\n",
    "                    })\n",
    "        else:\n",
    "            section_text = section_text.strip()\n",
    "            if section_text.endswith('.'):\n",
    "                section_text = section_text[:-1].strip()\n",
    "            \n",
    "            if section_text:\n",
    "                definitions.append({\n",
    "                    'definition': section_text,\n",
    "                    'pos_display': current_pos,\n",
    "                    'number': None,\n",
    "                    'pos': None,\n",
    "                    'gender': None,\n",
    "                    'declension_class': None,\n",
    "                    'referenced_entry': None\n",
    "                })\n",
    "    \n",
    "    return definitions\n",
    "\n",
    "\n",
    "# Add definitions to all entries\n",
    "for entry in data:\n",
    "    entry['definitions'] = parse_definitions(entry)\n",
    "\n",
    "# Calculate metrics\n",
    "total_entries = len(data)\n",
    "entries_with_defs = sum(1 for entry in data if entry['definitions'])\n",
    "entries_without_defs = total_entries - entries_with_defs\n",
    "total_defs = sum(len(e['definitions']) for e in data)\n",
    "entries_with_null_pos = sum(1 for entry in data if entry['definitions'] and any(d['pos_display'] is None for d in entry['definitions']))\n",
    "\n",
    "print(f\"Total entries: {total_entries}\")\n",
    "print(f\"Entries with definitions: {entries_with_defs} ({entries_with_defs/total_entries*100:.1f}%)\")\n",
    "print(f\"Entries without definitions: {entries_without_defs} ({entries_without_defs/total_entries*100:.1f}%)\")\n",
    "print(f\"Entries with null POS: {entries_with_null_pos} ({entries_with_null_pos/total_entries*100:.1f}%)\")\n",
    "print(f\"Total definitions parsed: {total_defs}\")\n",
    "print(f\"Average definitions per entry: {total_defs/total_entries:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "47409c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized 11819 definitions with POS\n",
      "Definitions without POS: 348\n",
      "\n",
      "Example normalized entry:\n",
      "{\n",
      "  \"entry_id\": \"berntsen_अ_1\",\n",
      "  \"headword_devanagari\": \"अ\",\n",
      "  \"headword_romanized\": \"a\",\n",
      "  \"full_entry\": \"अ a pref. negative.\",\n",
      "  \"source_page\": 1,\n",
      "  \"entry_type\": \"headword\",\n",
      "  \"base_word\": null,\n",
      "  \"search_text\": null,\n",
      "  \"definitions\": [\n",
      "    {\n",
      "      \"definition\": \"negative\",\n",
      "      \"pos_display\": \"pref.\",\n",
      "      \"number\": null,\n",
      "      \"pos\": \"prefix\",\n",
      "      \"gender\": null,\n",
      "      \"declension_class\": null,\n",
      "      \"referenced_entry\": null\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CELL 3: Normalize POS and Extract Gender\n",
    "# ==============================================================================\n",
    "# This cell:\n",
    "# - Converts pos_display (e.g., 'm.', 'f.(i)') to standardized pos (e.g., 'noun.masculine')\n",
    "# - Extracts gender from noun POS markers\n",
    "# - Extracts declension_class from markers like 'f.(i)', 'f.(e)'\n",
    "\n",
    "def normalize_pos(pos_display):\n",
    "    \"\"\"\n",
    "    Convert display POS to standardized POS, gender, and declension class.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (pos, gender, declension_class)\n",
    "    \"\"\"\n",
    "    if pos_display is None:\n",
    "        return None, None, None\n",
    "    \n",
    "    pos_mapping = {\n",
    "        # Nouns with gender\n",
    "        'm.': ('noun.masculine', 'masculine', None),\n",
    "        'f.': ('noun.feminine', 'feminine', None),\n",
    "        'n.': ('noun.neuter', 'neuter', None),\n",
    "        \n",
    "        # Nouns with declension class\n",
    "        'f.(i)': ('noun.feminine.i', 'feminine', 'i'),\n",
    "        'f.(e)': ('noun.feminine.e', 'feminine', 'e'),\n",
    "        'm.(i)': ('noun.masculine.i', 'masculine', 'i'),\n",
    "        'm.(e)': ('noun.masculine.e', 'masculine', 'e'),\n",
    "        \n",
    "        # Verbs\n",
    "        'v.t.': ('verb.transitive', None, None),\n",
    "        'v. t.': ('verb.transitive', None, None),\n",
    "        'v.i.': ('verb.intransitive', None, None),\n",
    "        'v. i.': ('verb.intransitive', None, None),\n",
    "        \n",
    "        # Adjectives\n",
    "        'adj.': ('adjective', None, None),\n",
    "        'adj. inv.': ('adjective.invariant', None, None),\n",
    "        'adj. suff.': ('adjective.suffix', None, None),\n",
    "        'adj. suff. inv.': ('adjective.suffix.invariant', None, None),\n",
    "        \n",
    "        # Adverbs\n",
    "        'adv.': ('adverb', None, None),\n",
    "        'adv. suff.': ('adverb.suffix', None, None),\n",
    "        \n",
    "        # Other POS\n",
    "        'pref.': ('prefix', None, None),\n",
    "        'suff.': ('suffix', None, None),\n",
    "        'n. suff.': ('noun.suffix', None, None),\n",
    "        'n.suff.': ('noun.suffix', None, None),\n",
    "        'm. suff.': ('noun.masculine.suffix', 'masculine', None),\n",
    "        'f. suff.': ('noun.feminine.suffix', 'feminine', None),\n",
    "        'conj.': ('conjunction', None, None),\n",
    "        'post.': ('postposition', None, None),\n",
    "        'pron.': ('pronoun', None, None),\n",
    "        'interj.': ('interjection', None, None),\n",
    "        'poss.': ('possessive', None, None),\n",
    "    }\n",
    "    \n",
    "    return pos_mapping.get(pos_display, (None, None, None))\n",
    "\n",
    "\n",
    "# Apply normalization to all definitions\n",
    "normalized_count = 0\n",
    "for entry in data:\n",
    "    for defn in entry['definitions']:\n",
    "        pos, gender, declension = normalize_pos(defn['pos_display'])\n",
    "        defn['pos'] = pos\n",
    "        defn['gender'] = gender\n",
    "        defn['declension_class'] = declension\n",
    "        if pos is not None:\n",
    "            normalized_count += 1\n",
    "\n",
    "print(f\"Normalized {normalized_count} definitions with POS\")\n",
    "print(f\"Definitions without POS: {total_defs - normalized_count}\")\n",
    "\n",
    "# Show example\n",
    "print(\"\\nExample normalized entry:\")\n",
    "example = next(e for e in data if e['definitions'] and e['definitions'][0]['pos'])\n",
    "print(json.dumps(example, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "51b6070f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-references processed: 81\n",
      "Cross-references not found: 2\n",
      "\n",
      "Cross-references not found (first 10):\n",
      "  भोकणे -> भुकंणे\n",
      "  सुरुवात -> सुरवात\n",
      "\n",
      "Example cross-reference:\n",
      "{\n",
      "  \"entry_id\": \"berntsen_अलीकडे_5\",\n",
      "  \"headword_devanagari\": \"अलीकडे\",\n",
      "  \"headword_romanized\": \"alīkaḍē\",\n",
      "  \"full_entry\": \"अलीकडे alīkaḍē See अलिकडे .\",\n",
      "  \"source_page\": 5,\n",
      "  \"entry_type\": \"headword\",\n",
      "  \"base_word\": null,\n",
      "  \"search_text\": null,\n",
      "  \"definitions\": [\n",
      "    {\n",
      "      \"definition\": \"See अलिकडे\",\n",
      "      \"pos_display\": null,\n",
      "      \"number\": null,\n",
      "      \"pos\": null,\n",
      "      \"gender\": null,\n",
      "      \"declension_class\": null,\n",
      "      \"referenced_entry\": {\n",
      "        \"relationship\": \"cross_reference\",\n",
      "        \"grammatical_form\": null,\n",
      "        \"entry_id\": \"berntsen_अलिकडे_5\",\n",
      "        \"headword_devanagari\": \"अलिकडे\",\n",
      "        \"headword_romanized\": \"alikaḍē\",\n",
      "        \"full_entry\": \"अलिकडे alikaḍē adv. 1. on this side. 2. recently. post. on this side.\",\n",
      "        \"source_page\": 5,\n",
      "        \"definitions\": [\n",
      "          {\n",
      "            \"definition\": \"on this side\",\n",
      "            \"pos_display\": \"adv.\",\n",
      "            \"number\": 1,\n",
      "            \"pos\": \"adverb\",\n",
      "            \"gender\": null,\n",
      "            \"declension_class\": null,\n",
      "            \"referenced_entry\": null\n",
      "          },\n",
      "          {\n",
      "            \"definition\": \"recently\",\n",
      "            \"pos_display\": \"adv.\",\n",
      "            \"number\": 2,\n",
      "            \"pos\": \"adverb\",\n",
      "            \"gender\": null,\n",
      "            \"declension_class\": null,\n",
      "            \"referenced_entry\": null\n",
      "          },\n",
      "          {\n",
      "            \"definition\": \"on this side\",\n",
      "            \"pos_display\": \"post.\",\n",
      "            \"number\": null,\n",
      "            \"pos\": \"postposition\",\n",
      "            \"gender\": null,\n",
      "            \"declension_class\": null,\n",
      "            \"referenced_entry\": null\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CELL 4: Process Cross-References (\"See X\")\n",
    "# ==============================================================================\n",
    "# This cell:\n",
    "# - Finds definitions that are cross-references (e.g., \"See हुजत\")\n",
    "# - Looks up the referenced entry in the dictionary\n",
    "# - Populates referenced_entry with relationship: 'cross_reference'\n",
    "# - Embeds the full referenced entry for self-contained RAG chunks\n",
    "\n",
    "import re\n",
    "\n",
    "def find_entry_by_headword(headword_devanagari, data):\n",
    "    \"\"\"Find an entry by its Devanagari headword.\"\"\"\n",
    "    for entry in data:\n",
    "        if entry['headword_devanagari'] == headword_devanagari:\n",
    "            return entry\n",
    "    return None\n",
    "\n",
    "\n",
    "def create_referenced_entry(source_entry, relationship, grammatical_form=None):\n",
    "    \"\"\"\n",
    "    Create a referenced_entry object from a source entry.\n",
    "    \n",
    "    Args:\n",
    "        source_entry: The entry being referenced\n",
    "        relationship: Type of relationship (cross_reference, base_form, etc.)\n",
    "        grammatical_form: Optional grammatical form (perfective, plural, etc.)\n",
    "    \n",
    "    Returns:\n",
    "        OrderedDict with referenced entry structure\n",
    "    \"\"\"\n",
    "    if source_entry is None:\n",
    "        return None\n",
    "    \n",
    "    ref = OrderedDict()\n",
    "    ref['relationship'] = relationship\n",
    "    ref['grammatical_form'] = grammatical_form\n",
    "    ref['entry_id'] = source_entry['entry_id']\n",
    "    ref['headword_devanagari'] = source_entry['headword_devanagari']\n",
    "    ref['headword_romanized'] = source_entry['headword_romanized']\n",
    "    ref['full_entry'] = source_entry['full_entry']\n",
    "    ref['source_page'] = source_entry['source_page']\n",
    "    ref['definitions'] = deepcopy(source_entry['definitions'])\n",
    "    \n",
    "    return ref\n",
    "\n",
    "\n",
    "# Pattern to match \"See X\" where X is Devanagari\n",
    "# Also handles \"See X , def. 1\" format\n",
    "see_pattern = re.compile(r'^See\\s+([\\u0900-\\u097F]+)(?:\\s*,\\s*def\\.\\s*(\\d+))?\\.?$')\n",
    "\n",
    "cross_ref_count = 0\n",
    "cross_ref_not_found = []\n",
    "\n",
    "for entry in data:\n",
    "    for defn in entry['definitions']:\n",
    "        match = see_pattern.match(defn['definition'])\n",
    "        if match:\n",
    "            referenced_headword = match.group(1)\n",
    "            def_number = match.group(2)  # May be None\n",
    "            \n",
    "            # Find the referenced entry\n",
    "            referenced_entry = find_entry_by_headword(referenced_headword, data)\n",
    "            \n",
    "            if referenced_entry:\n",
    "                defn['referenced_entry'] = create_referenced_entry(\n",
    "                    referenced_entry, \n",
    "                    relationship='cross_reference'\n",
    "                )\n",
    "                cross_ref_count += 1\n",
    "            else:\n",
    "                cross_ref_not_found.append({\n",
    "                    'entry': entry['headword_devanagari'],\n",
    "                    'looking_for': referenced_headword\n",
    "                })\n",
    "\n",
    "print(f\"Cross-references processed: {cross_ref_count}\")\n",
    "print(f\"Cross-references not found: {len(cross_ref_not_found)}\")\n",
    "\n",
    "if cross_ref_not_found:\n",
    "    print(\"\\nCross-references not found (first 10):\")\n",
    "    for item in cross_ref_not_found[:10]:\n",
    "        print(f\"  {item['entry']} -> {item['looking_for']}\")\n",
    "\n",
    "# Verify with example\n",
    "print(\"\\nExample cross-reference:\")\n",
    "example = next((e for e in data if e['definitions'] and \n",
    "                e['definitions'][0].get('referenced_entry') and\n",
    "                e['definitions'][0]['referenced_entry']['relationship'] == 'cross_reference'), None)\n",
    "if example:\n",
    "    print(json.dumps(example, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a5f177ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammatical forms processed: 39\n",
      "Grammatical forms not found: 0\n",
      "\n",
      "Grammatical forms by type:\n",
      "  perfective: 18\n",
      "  possessive_of: 8\n",
      "  plural: 3\n",
      "  oblique: 3\n",
      "  past_tense: 2\n",
      "  present_tense: 1\n",
      "  instrumental: 1\n",
      "  vocative_singular: 1\n",
      "  negative: 1\n",
      "  plural_oblique: 1\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CELL 5: Process Grammatical Forms\n",
    "# ==============================================================================\n",
    "# This cell:\n",
    "# - Finds definitions that reference base forms (e.g., \"perf. of गाणे\")\n",
    "# - Handles: perf. of, past tense of, pres. of, hab. of, negative of,\n",
    "#   obl. of, instr. of, loc. of, voc. sg. of, pl. of\n",
    "# - Populates referenced_entry with relationship: 'base_form'\n",
    "# - Includes grammatical_form field (e.g., 'perfective', 'plural')\n",
    "\n",
    "import re\n",
    "\n",
    "# Pattern to match grammatical form references\n",
    "# Captures: (grammatical indicator) of (Devanagari word)\n",
    "grammatical_patterns = [\n",
    "    (r'^perf\\.\\s+of\\s+([\\u0900-\\u097F]+)\\.?$', 'perfective'),\n",
    "    (r'^past tense of\\s+([\\u0900-\\u097F]+)\\.?$', 'past_tense'),\n",
    "    (r'^pres\\.\\s+of\\s+([\\u0900-\\u097F]+)\\.?$', 'present_tense'),\n",
    "    (r'^hab\\.\\s+of\\s+([\\u0900-\\u097F]+)\\.?$', 'habitual'),\n",
    "    (r'^negative of\\s+([\\u0900-\\u097F]+)\\.?$', 'negative'),\n",
    "    (r'^obl\\.?\\s*(?:form\\s+)?of\\s+([\\u0900-\\u097F]+)\\.?$', 'oblique'),\n",
    "    (r'^instr\\.\\s+of\\s+([\\u0900-\\u097F]+)\\.?$', 'instrumental'),\n",
    "    (r'^loc\\.\\s+of\\s+([\\u0900-\\u097F]+)\\.?$', 'locative'),\n",
    "    (r'^voc\\.\\s+sg\\.\\s+of\\s+([\\u0900-\\u097F]+)\\.?$', 'vocative_singular'),\n",
    "    (r'^pl\\.\\s+of\\s+([\\u0900-\\u097F]+)\\.?$', 'plural'),\n",
    "    (r'^pl\\.\\s+and\\s+obl\\.\\s+of\\s+([\\u0900-\\u097F]+)\\.?$', 'plural_oblique'),\n",
    "    (r'^of\\s+([\\u0900-\\u097F]+)$', 'possessive_of'),  # For possessives like \"of आम्ही\"\n",
    "]\n",
    "\n",
    "# Compile patterns\n",
    "compiled_patterns = [(re.compile(pattern, re.IGNORECASE), form) for pattern, form in grammatical_patterns]\n",
    "\n",
    "grammatical_count = 0\n",
    "grammatical_not_found = []\n",
    "\n",
    "for entry in data:\n",
    "    for defn in entry['definitions']:\n",
    "        # Skip if already has a referenced_entry (e.g., cross-reference)\n",
    "        if defn['referenced_entry'] is not None:\n",
    "            continue\n",
    "        \n",
    "        definition = defn['definition']\n",
    "        \n",
    "        for pattern, grammatical_form in compiled_patterns:\n",
    "            match = pattern.match(definition)\n",
    "            if match:\n",
    "                referenced_headword = match.group(1)\n",
    "                \n",
    "                # Find the referenced entry\n",
    "                referenced_entry = find_entry_by_headword(referenced_headword, data)\n",
    "                \n",
    "                if referenced_entry:\n",
    "                    defn['referenced_entry'] = create_referenced_entry(\n",
    "                        referenced_entry,\n",
    "                        relationship='base_form',\n",
    "                        grammatical_form=grammatical_form\n",
    "                    )\n",
    "                    grammatical_count += 1\n",
    "                else:\n",
    "                    grammatical_not_found.append({\n",
    "                        'entry': entry['headword_devanagari'],\n",
    "                        'looking_for': referenced_headword,\n",
    "                        'form': grammatical_form\n",
    "                    })\n",
    "                break  # Found a match, no need to check other patterns\n",
    "\n",
    "print(f\"Grammatical forms processed: {grammatical_count}\")\n",
    "print(f\"Grammatical forms not found: {len(grammatical_not_found)}\")\n",
    "\n",
    "if grammatical_not_found:\n",
    "    print(\"\\nGrammatical forms not found (first 10):\")\n",
    "    for item in grammatical_not_found[:10]:\n",
    "        print(f\"  {item['entry']} -> {item['looking_for']} ({item['form']})\")\n",
    "\n",
    "# Show counts by grammatical form\n",
    "form_counts = {}\n",
    "for entry in data:\n",
    "    for defn in entry['definitions']:\n",
    "        ref = defn.get('referenced_entry')\n",
    "        if ref and ref['relationship'] == 'base_form':\n",
    "            form = ref['grammatical_form']\n",
    "            form_counts[form] = form_counts.get(form, 0) + 1\n",
    "\n",
    "print(\"\\nGrammatical forms by type:\")\n",
    "for form, count in sorted(form_counts.items(), key=lambda x: -x[1]):\n",
    "    print(f\"  {form}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ce073e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduplications processed: 16\n",
      "Reduplications not found: 1\n",
      "\n",
      "Reduplications not found:\n",
      "  निजानीज -> नीज\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CELL 6: Process Reduplications\n",
    "# ==============================================================================\n",
    "# This cell:\n",
    "# - Finds definitions that are reduplications (e.g., \"redupl. of खरे\")\n",
    "# - Handles: redupl. of, redupl. loc. of\n",
    "# - Populates referenced_entry with relationship: 'reduplication_of'\n",
    "\n",
    "import re\n",
    "\n",
    "# Patterns for reduplication\n",
    "redupl_patterns = [\n",
    "    (r'^redupl\\.\\s+of\\s+([\\u0900-\\u097F]+)\\.?(?:\\s+.*)?$', None),\n",
    "    (r'^redupl\\.\\s+loc\\.\\s+of\\s+([\\u0900-\\u097F]+)\\.?(?:\\s+.*)?$', 'locative'),\n",
    "]\n",
    "\n",
    "compiled_redupl = [(re.compile(pattern, re.IGNORECASE), form) for pattern, form in redupl_patterns]\n",
    "\n",
    "redupl_count = 0\n",
    "redupl_not_found = []\n",
    "\n",
    "for entry in data:\n",
    "    for defn in entry['definitions']:\n",
    "        # Skip if already has a referenced_entry\n",
    "        if defn['referenced_entry'] is not None:\n",
    "            continue\n",
    "        \n",
    "        definition = defn['definition']\n",
    "        \n",
    "        for pattern, grammatical_form in compiled_redupl:\n",
    "            match = pattern.match(definition)\n",
    "            if match:\n",
    "                referenced_headword = match.group(1)\n",
    "                \n",
    "                referenced_entry = find_entry_by_headword(referenced_headword, data)\n",
    "                \n",
    "                if referenced_entry:\n",
    "                    defn['referenced_entry'] = create_referenced_entry(\n",
    "                        referenced_entry,\n",
    "                        relationship='reduplication_of',\n",
    "                        grammatical_form=grammatical_form\n",
    "                    )\n",
    "                    redupl_count += 1\n",
    "                else:\n",
    "                    redupl_not_found.append({\n",
    "                        'entry': entry['headword_devanagari'],\n",
    "                        'looking_for': referenced_headword\n",
    "                    })\n",
    "                break\n",
    "\n",
    "print(f\"Reduplications processed: {redupl_count}\")\n",
    "print(f\"Reduplications not found: {len(redupl_not_found)}\")\n",
    "\n",
    "if redupl_not_found:\n",
    "    print(\"\\nReduplications not found:\")\n",
    "    for item in redupl_not_found:\n",
    "        print(f\"  {item['entry']} -> {item['looking_for']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6b7b7516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abbreviations processed: 4\n",
      "Abbreviations not found: 0\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CELL 7: Process Abbreviations\n",
    "# ==============================================================================\n",
    "# This cell:\n",
    "# - Finds definitions that are abbreviations (e.g., \"abbrev. of इत्यादी\")\n",
    "# - Populates referenced_entry with relationship: 'abbreviation_of'\n",
    "\n",
    "import re\n",
    "\n",
    "# Pattern for abbreviations\n",
    "abbrev_pattern = re.compile(r'^abbrev\\.?\\s+of\\.?\\s+([\\u0900-\\u097F]+)\\.?$', re.IGNORECASE)\n",
    "\n",
    "abbrev_count = 0\n",
    "abbrev_not_found = []\n",
    "\n",
    "for entry in data:\n",
    "    for defn in entry['definitions']:\n",
    "        # Skip if already has a referenced_entry\n",
    "        if defn['referenced_entry'] is not None:\n",
    "            continue\n",
    "        \n",
    "        definition = defn['definition']\n",
    "        match = abbrev_pattern.match(definition)\n",
    "        \n",
    "        if match:\n",
    "            referenced_headword = match.group(1)\n",
    "            \n",
    "            referenced_entry = find_entry_by_headword(referenced_headword, data)\n",
    "            \n",
    "            if referenced_entry:\n",
    "                defn['referenced_entry'] = create_referenced_entry(\n",
    "                    referenced_entry,\n",
    "                    relationship='abbreviation_of'\n",
    "                )\n",
    "                abbrev_count += 1\n",
    "            else:\n",
    "                abbrev_not_found.append({\n",
    "                    'entry': entry['headword_devanagari'],\n",
    "                    'looking_for': referenced_headword\n",
    "                })\n",
    "\n",
    "print(f\"Abbreviations processed: {abbrev_count}\")\n",
    "print(f\"Abbreviations not found: {len(abbrev_not_found)}\")\n",
    "\n",
    "if abbrev_not_found:\n",
    "    print(\"\\nAbbreviations not found:\")\n",
    "    for item in abbrev_not_found:\n",
    "        print(f\"  {item['entry']} -> {item['looking_for']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1721723a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variants processed: 0\n",
      "Variants not found: 1\n",
      "\n",
      "Variants not found:\n",
      "  मज -> माझ्या\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CELL 8: Process Variants\n",
    "# ==============================================================================\n",
    "# This cell:\n",
    "# - Finds definitions that are variants (e.g., \"var. of माझ्या\")\n",
    "# - Populates referenced_entry with relationship: 'variant_of'\n",
    "\n",
    "import re\n",
    "\n",
    "# Pattern for variants\n",
    "variant_pattern = re.compile(r'^var\\.?\\s+of\\s+([\\u0900-\\u097F]+)\\.?$', re.IGNORECASE)\n",
    "\n",
    "variant_count = 0\n",
    "variant_not_found = []\n",
    "\n",
    "for entry in data:\n",
    "    for defn in entry['definitions']:\n",
    "        # Skip if already has a referenced_entry\n",
    "        if defn['referenced_entry'] is not None:\n",
    "            continue\n",
    "        \n",
    "        definition = defn['definition']\n",
    "        match = variant_pattern.match(definition)\n",
    "        \n",
    "        if match:\n",
    "            referenced_headword = match.group(1)\n",
    "            \n",
    "            referenced_entry = find_entry_by_headword(referenced_headword, data)\n",
    "            \n",
    "            if referenced_entry:\n",
    "                defn['referenced_entry'] = create_referenced_entry(\n",
    "                    referenced_entry,\n",
    "                    relationship='variant_of'\n",
    "                )\n",
    "                variant_count += 1\n",
    "            else:\n",
    "                variant_not_found.append({\n",
    "                    'entry': entry['headword_devanagari'],\n",
    "                    'looking_for': referenced_headword\n",
    "                })\n",
    "\n",
    "print(f\"Variants processed: {variant_count}\")\n",
    "print(f\"Variants not found: {len(variant_not_found)}\")\n",
    "\n",
    "if variant_not_found:\n",
    "    print(\"\\nVariants not found:\")\n",
    "    for item in variant_not_found:\n",
    "        print(f\"  {item['entry']} -> {item['looking_for']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "425f81af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries containing collocations: 486\n",
      "Collocation entries created: 619\n",
      "Total entries now: 10455\n",
      "\n",
      "Example collocation entries (first 3):\n",
      "{\n",
      "  \"entry_id\": \"berntsen_अखेर_1_c1\",\n",
      "  \"headword_devanagari\": \"अखेर चे\",\n",
      "  \"headword_romanized\": null,\n",
      "  \"full_entry\": \"अखेर चे final\",\n",
      "  \"source_page\": 1,\n",
      "  \"entry_type\": \"collocation\",\n",
      "  \"definitions\": [\n",
      "    {\n",
      "      \"definition\": \"final\",\n",
      "      \"pos_display\": null,\n",
      "      \"number\": null,\n",
      "      \"pos\": null,\n",
      "      \"gender\": null,\n",
      "      \"declension_class\": null,\n",
      "      \"referenced_entry\": null\n",
      "    }\n",
      "  ],\n",
      "  \"base_word\": {\n",
      "    \"entry_id\": \"berntsen_अखेर_1\",\n",
      "    \"headword_devanagari\": \"अखेर\",\n",
      "    \"headword_romanized\": \"akhēra\",\n",
      "    \"definition\": \"end; finally.\",\n",
      "    \"pos\": \"noun.feminine.i\"\n",
      "  },\n",
      "  \"search_text\": null\n",
      "}\n",
      "\n",
      "{\n",
      "  \"entry_id\": \"berntsen_अंग_1_c1\",\n",
      "  \"headword_devanagari\": \"अंग चे\",\n",
      "  \"headword_romanized\": null,\n",
      "  \"full_entry\": \"अंग चे natural, inborn.\",\n",
      "  \"source_page\": 1,\n",
      "  \"entry_type\": \"collocation\",\n",
      "  \"definitions\": [\n",
      "    {\n",
      "      \"definition\": \"natural, inborn.\",\n",
      "      \"pos_display\": null,\n",
      "      \"number\": null,\n",
      "      \"pos\": null,\n",
      "      \"gender\": null,\n",
      "      \"declension_class\": null,\n",
      "      \"referenced_entry\": null\n",
      "    }\n",
      "  ],\n",
      "  \"base_word\": {\n",
      "    \"entry_id\": \"berntsen_अंग_1\",\n",
      "    \"headword_devanagari\": \"अंग\",\n",
      "    \"headword_romanized\": \"aṅga\",\n",
      "    \"definition\": \"body; part; side; capacity, skill.\",\n",
      "    \"pos\": \"noun.neuter\"\n",
      "  },\n",
      "  \"search_text\": null\n",
      "}\n",
      "\n",
      "{\n",
      "  \"entry_id\": \"berntsen_अंग_1_c2\",\n",
      "  \"headword_devanagari\": \"अंग चोरणे\",\n",
      "  \"headword_romanized\": null,\n",
      "  \"full_entry\": \"अंग चोरणे to contract one's body, shirk.\",\n",
      "  \"source_page\": 1,\n",
      "  \"entry_type\": \"collocation\",\n",
      "  \"definitions\": [\n",
      "    {\n",
      "      \"definition\": \"to contract one's body, shirk.\",\n",
      "      \"pos_display\": null,\n",
      "      \"number\": null,\n",
      "      \"pos\": null,\n",
      "      \"gender\": null,\n",
      "      \"declension_class\": null,\n",
      "      \"referenced_entry\": null\n",
      "    }\n",
      "  ],\n",
      "  \"base_word\": {\n",
      "    \"entry_id\": \"berntsen_अंग_1\",\n",
      "    \"headword_devanagari\": \"अंग\",\n",
      "    \"headword_romanized\": \"aṅga\",\n",
      "    \"definition\": \"body; part; side; capacity, skill.\",\n",
      "    \"pos\": \"noun.neuter\"\n",
      "  },\n",
      "  \"search_text\": null\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CELL 9: Process Collocations (Create New Entries)\n",
    "# ==============================================================================\n",
    "# This cell:\n",
    "# - Finds definitions with collocation patterns (e.g., \"० करणे to urge\")\n",
    "# - Creates NEW entries for each collocation with entry_type: 'collocation'\n",
    "# - Populates base_word with the parent entry's information\n",
    "# - Handles multiple verbs (e.g., \"० मारणे , टाकणे , घेणे to jump\")\n",
    "#   by creating separate entries for each verb\n",
    "# - Adds new collocation entries to the data list\n",
    "\n",
    "import re\n",
    "\n",
    "def parse_collocation(definition_text, headword_devanagari, headword_romanized):\n",
    "    \"\"\"\n",
    "    Parse a definition containing collocation pattern(s).\n",
    "    \n",
    "    Args:\n",
    "        definition_text: The definition string containing ०\n",
    "        headword_devanagari: The headword in Devanagari\n",
    "        headword_romanized: The headword romanized\n",
    "    \n",
    "    Returns:\n",
    "        List of collocation dicts with: phrase_devanagari, phrase_romanized, meaning\n",
    "        Returns empty list if no collocations found\n",
    "    \"\"\"\n",
    "    collocations = []\n",
    "    \n",
    "    # Pattern: ० followed by verb(s) and meaning\n",
    "    # Examples:\n",
    "    #   \"० करणे to urge\"\n",
    "    #   \"० मारणे , टाकणे , घेणे to jump\"\n",
    "    #   \"० चे final\"\n",
    "    \n",
    "    # Find all ० patterns in the definition\n",
    "    # Split definition by ० to find collocation parts\n",
    "    if '०' not in definition_text:\n",
    "        return []\n",
    "    \n",
    "    # Split on ० and process each part\n",
    "    parts = definition_text.split('०')\n",
    "    \n",
    "    for part in parts[1:]:  # Skip the part before first ०\n",
    "        part = part.strip()\n",
    "        if not part:\n",
    "            continue\n",
    "        \n",
    "        # Try to extract verb(s) and meaning\n",
    "        # Pattern: verb(s) followed by English meaning\n",
    "        # Verbs are Devanagari words, meaning is English\n",
    "        \n",
    "        # Match: Devanagari word(s) possibly separated by commas, then English text\n",
    "        match = re.match(\n",
    "            r'^([\\u0900-\\u097F]+(?:\\s*,\\s*[\\u0900-\\u097F]+)*)\\s+(.+)$',\n",
    "            part\n",
    "        )\n",
    "        \n",
    "        if match:\n",
    "            verbs_part = match.group(1)\n",
    "            meaning = match.group(2).strip()\n",
    "            \n",
    "            # Split verbs by comma\n",
    "            verbs = [v.strip() for v in verbs_part.split(',')]\n",
    "            \n",
    "            for verb in verbs:\n",
    "                if verb:\n",
    "                    # Create full phrase\n",
    "                    phrase_devanagari = f\"{headword_devanagari} {verb}\"\n",
    "                    \n",
    "                    collocations.append({\n",
    "                        'phrase_devanagari': phrase_devanagari,\n",
    "                        'verb': verb,\n",
    "                        'meaning': meaning\n",
    "                    })\n",
    "        else:\n",
    "            # Try simpler pattern: just \"चे something\" (attributive)\n",
    "            match2 = re.match(r'^([\\u0900-\\u097F]+)\\s*(.*)$', part)\n",
    "            if match2:\n",
    "                modifier = match2.group(1)\n",
    "                meaning = match2.group(2).strip() if match2.group(2) else ''\n",
    "                \n",
    "                phrase_devanagari = f\"{headword_devanagari} {modifier}\"\n",
    "                \n",
    "                collocations.append({\n",
    "                    'phrase_devanagari': phrase_devanagari,\n",
    "                    'verb': modifier,\n",
    "                    'meaning': meaning if meaning else modifier\n",
    "                })\n",
    "    \n",
    "    return collocations\n",
    "\n",
    "\n",
    "# Track statistics\n",
    "collocation_entries_created = 0\n",
    "entries_with_collocations = 0\n",
    "\n",
    "# Store new collocation entries to add\n",
    "new_collocation_entries = []\n",
    "\n",
    "for entry in data:\n",
    "    entry_has_collocation = False\n",
    "    \n",
    "    for defn in entry['definitions']:\n",
    "        definition = defn['definition']\n",
    "        \n",
    "        # Check if definition contains ०\n",
    "        if '०' not in definition:\n",
    "            continue\n",
    "        \n",
    "        entry_has_collocation = True\n",
    "        \n",
    "        # Parse collocations from this definition\n",
    "        collocations = parse_collocation(\n",
    "            definition,\n",
    "            entry['headword_devanagari'],\n",
    "            entry['headword_romanized']\n",
    "        )\n",
    "        \n",
    "        # Create new entry for each collocation\n",
    "        for i, colloc in enumerate(collocations):\n",
    "            new_entry = OrderedDict()\n",
    "            \n",
    "            # Generate unique entry_id\n",
    "            new_entry['entry_id'] = f\"{entry['entry_id']}_c{i+1}\"\n",
    "            new_entry['headword_devanagari'] = colloc['phrase_devanagari']\n",
    "            new_entry['headword_romanized'] = None  # Would need transliteration\n",
    "            new_entry['full_entry'] = f\"{colloc['phrase_devanagari']} {colloc['meaning']}\"\n",
    "            new_entry['source_page'] = entry['source_page']\n",
    "            new_entry['entry_type'] = 'collocation'\n",
    "            \n",
    "            # Create definition for the collocation\n",
    "            new_entry['definitions'] = [{\n",
    "                'definition': colloc['meaning'],\n",
    "                'pos_display': None,\n",
    "                'number': None,\n",
    "                'pos': None,  # Could infer verb.phrase but leaving null per discussion\n",
    "                'gender': None,\n",
    "                'declension_class': None,\n",
    "                'referenced_entry': None\n",
    "            }]\n",
    "            \n",
    "            # Populate base_word with parent entry info\n",
    "            # Flatten the definition for base_word\n",
    "            base_definitions = [d['definition'] for d in entry['definitions']]\n",
    "            base_def_text = '; '.join(base_definitions)\n",
    "            # Remove collocation patterns from base definition for cleaner text\n",
    "            base_def_clean = re.sub(r'०[^०]*(?=०|$)', '', base_def_text).strip()\n",
    "            base_def_clean = re.sub(r'\\s+', ' ', base_def_clean).strip('; ')\n",
    "            \n",
    "            new_entry['base_word'] = OrderedDict()\n",
    "            new_entry['base_word']['entry_id'] = entry['entry_id']\n",
    "            new_entry['base_word']['headword_devanagari'] = entry['headword_devanagari']\n",
    "            new_entry['base_word']['headword_romanized'] = entry['headword_romanized']\n",
    "            new_entry['base_word']['definition'] = base_def_clean if base_def_clean else base_def_text\n",
    "            new_entry['base_word']['pos'] = entry['definitions'][0]['pos'] if entry['definitions'] else None\n",
    "            \n",
    "            new_entry['search_text'] = None  # Computed later\n",
    "            \n",
    "            new_collocation_entries.append(new_entry)\n",
    "            collocation_entries_created += 1\n",
    "    \n",
    "    if entry_has_collocation:\n",
    "        entries_with_collocations += 1\n",
    "\n",
    "# Add new collocation entries to data\n",
    "data.extend(new_collocation_entries)\n",
    "\n",
    "print(f\"Entries containing collocations: {entries_with_collocations}\")\n",
    "print(f\"Collocation entries created: {collocation_entries_created}\")\n",
    "print(f\"Total entries now: {len(data)}\")\n",
    "\n",
    "# Show examples\n",
    "print(\"\\nExample collocation entries (first 3):\")\n",
    "colloc_examples = [e for e in data if e['entry_type'] == 'collocation'][:3]\n",
    "for ex in colloc_examples:\n",
    "    print(json.dumps(ex, ensure_ascii=False, indent=2))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4342e009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_text built for all entries\n",
      "\n",
      "Total entries: 10455\n",
      "\n",
      "================================================================================\n",
      "Example search_text (headword entry):\n",
      "================================================================================\n",
      "Entry: अ\n",
      "search_text: अ a headword negative prefix...\n",
      "\n",
      "================================================================================\n",
      "Example search_text (entry with referenced_entry):\n",
      "================================================================================\n",
      "Entry: अलीकडे\n",
      "search_text: अलीकडे alīkaḍē headword See अलिकडे cross_reference अलिकडे alikaḍē on this side adverb recently adverb on this side postposition...\n",
      "\n",
      "================================================================================\n",
      "Example search_text (collocation entry):\n",
      "================================================================================\n",
      "Entry: अखेर चे\n",
      "search_text: अखेर चे collocation final अखेर akhēra end; finally. noun.feminine.i\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CELL 10: Build search_text\n",
    "# ==============================================================================\n",
    "# This cell:\n",
    "# - Constructs the search_text field for each entry\n",
    "# - Concatenates all relevant fields for vector embedding\n",
    "# - For entries with referenced_entry, includes the referenced entry's info\n",
    "# - For collocations, includes base_word info\n",
    "\n",
    "def build_search_text(entry):\n",
    "    \"\"\"\n",
    "    Build a comprehensive search_text for vector embedding.\n",
    "    \n",
    "    Includes:\n",
    "    - Headword (Devanagari and romanized)\n",
    "    - All definitions\n",
    "    - POS information\n",
    "    - Referenced entry info (if present)\n",
    "    - Base word info (for collocations)\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    \n",
    "    # Add headword\n",
    "    parts.append(entry['headword_devanagari'])\n",
    "    if entry['headword_romanized']:\n",
    "        parts.append(entry['headword_romanized'])\n",
    "    \n",
    "    # Add entry type\n",
    "    parts.append(entry['entry_type'])\n",
    "    \n",
    "    # Add definitions and their metadata\n",
    "    for defn in entry['definitions']:\n",
    "        parts.append(defn['definition'])\n",
    "        \n",
    "        if defn['pos']:\n",
    "            parts.append(defn['pos'])\n",
    "        \n",
    "        if defn['gender']:\n",
    "            parts.append(defn['gender'])\n",
    "        \n",
    "        # Add referenced entry info\n",
    "        ref = defn.get('referenced_entry')\n",
    "        if ref:\n",
    "            parts.append(ref['relationship'])\n",
    "            if ref['grammatical_form']:\n",
    "                parts.append(ref['grammatical_form'])\n",
    "            parts.append(ref['headword_devanagari'])\n",
    "            if ref['headword_romanized']:\n",
    "                parts.append(ref['headword_romanized'])\n",
    "            # Add referenced definitions\n",
    "            for ref_defn in ref.get('definitions', []):\n",
    "                parts.append(ref_defn['definition'])\n",
    "                if ref_defn.get('pos'):\n",
    "                    parts.append(ref_defn['pos'])\n",
    "    \n",
    "    # Add base_word info for collocations\n",
    "    base = entry.get('base_word')\n",
    "    if base:\n",
    "        parts.append(base['headword_devanagari'])\n",
    "        if base['headword_romanized']:\n",
    "            parts.append(base['headword_romanized'])\n",
    "        parts.append(base['definition'])\n",
    "        if base['pos']:\n",
    "            parts.append(base['pos'])\n",
    "    \n",
    "    # Join all parts with spaces\n",
    "    search_text = ' '.join(str(p) for p in parts if p)\n",
    "    \n",
    "    # Clean up multiple spaces\n",
    "    search_text = re.sub(r'\\s+', ' ', search_text).strip()\n",
    "    \n",
    "    return search_text\n",
    "\n",
    "\n",
    "# Build search_text for all entries\n",
    "for entry in data:\n",
    "    entry['search_text'] = build_search_text(entry)\n",
    "\n",
    "# Verify\n",
    "print(\"search_text built for all entries\")\n",
    "print(f\"\\nTotal entries: {len(data)}\")\n",
    "\n",
    "# Show examples\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Example search_text (headword entry):\")\n",
    "print(\"=\"*80)\n",
    "headword_example = next(e for e in data if e['entry_type'] == 'headword' and e['definitions'])\n",
    "print(f\"Entry: {headword_example['headword_devanagari']}\")\n",
    "print(f\"search_text: {headword_example['search_text'][:200]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Example search_text (entry with referenced_entry):\")\n",
    "print(\"=\"*80)\n",
    "ref_example = next((e for e in data if e['definitions'] and \n",
    "                    e['definitions'][0].get('referenced_entry')), None)\n",
    "if ref_example:\n",
    "    print(f\"Entry: {ref_example['headword_devanagari']}\")\n",
    "    print(f\"search_text: {ref_example['search_text'][:300]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Example search_text (collocation entry):\")\n",
    "print(\"=\"*80)\n",
    "colloc_example = next((e for e in data if e['entry_type'] == 'collocation'), None)\n",
    "if colloc_example:\n",
    "    print(f\"Entry: {colloc_example['headword_devanagari']}\")\n",
    "    print(f\"search_text: {colloc_example['search_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c8223222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FINAL PROCESSING SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Total entries: 10455\n",
      "  - Headword entries: 9836\n",
      "  - Collocation entries: 619\n",
      "\n",
      "Referenced entries by relationship:\n",
      "  - cross_reference: 81\n",
      "  - base_form: 39\n",
      "  - reduplication_of: 16\n",
      "  - abbreviation_of: 4\n",
      "\n",
      "Entries with search_text: 10455\n",
      "Average search_text length: 69.5 characters\n",
      "\n",
      "Entries with base_word: 619\n",
      "\n",
      "================================================================================\n",
      "SCHEMA VERIFICATION\n",
      "================================================================================\n",
      "✓ All entries have required fields\n",
      "✓ All definitions have required fields\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CELL 11: Summary Statistics\n",
    "# ==============================================================================\n",
    "# This cell:\n",
    "# - Provides final statistics on processed data\n",
    "# - Counts entries by type\n",
    "# - Counts referenced_entry by relationship type\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FINAL PROCESSING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Entry type counts\n",
    "headword_count = sum(1 for e in data if e['entry_type'] == 'headword')\n",
    "collocation_count = sum(1 for e in data if e['entry_type'] == 'collocation')\n",
    "\n",
    "print(f\"\\nTotal entries: {len(data)}\")\n",
    "print(f\"  - Headword entries: {headword_count}\")\n",
    "print(f\"  - Collocation entries: {collocation_count}\")\n",
    "\n",
    "# Referenced entry counts by relationship\n",
    "relationship_counts = {}\n",
    "for entry in data:\n",
    "    for defn in entry['definitions']:\n",
    "        ref = defn.get('referenced_entry')\n",
    "        if ref:\n",
    "            rel = ref['relationship']\n",
    "            relationship_counts[rel] = relationship_counts.get(rel, 0) + 1\n",
    "\n",
    "print(f\"\\nReferenced entries by relationship:\")\n",
    "for rel, count in sorted(relationship_counts.items(), key=lambda x: -x[1]):\n",
    "    print(f\"  - {rel}: {count}\")\n",
    "\n",
    "# Entries with search_text\n",
    "has_search_text = sum(1 for e in data if e['search_text'])\n",
    "print(f\"\\nEntries with search_text: {has_search_text}\")\n",
    "\n",
    "# Average search_text length\n",
    "avg_len = sum(len(e['search_text']) for e in data if e['search_text']) / has_search_text\n",
    "print(f\"Average search_text length: {avg_len:.1f} characters\")\n",
    "\n",
    "# Entries with base_word (collocations)\n",
    "has_base_word = sum(1 for e in data if e['base_word'])\n",
    "print(f\"\\nEntries with base_word: {has_base_word}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SCHEMA VERIFICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Verify all entries have required fields\n",
    "required_fields = ['entry_id', 'headword_devanagari', 'headword_romanized', \n",
    "                   'full_entry', 'source_page', 'entry_type', 'definitions',\n",
    "                   'base_word', 'search_text']\n",
    "\n",
    "missing_fields = []\n",
    "for entry in data:\n",
    "    for field in required_fields:\n",
    "        if field not in entry:\n",
    "            missing_fields.append((entry['entry_id'], field))\n",
    "\n",
    "if missing_fields:\n",
    "    print(f\"WARNING: {len(missing_fields)} entries missing required fields\")\n",
    "    for entry_id, field in missing_fields[:10]:\n",
    "        print(f\"  {entry_id} missing {field}\")\n",
    "else:\n",
    "    print(\"✓ All entries have required fields\")\n",
    "\n",
    "# Verify definition schema\n",
    "def_required = ['definition', 'pos_display', 'number', 'pos', 'gender', \n",
    "                'declension_class', 'referenced_entry']\n",
    "\n",
    "def_missing = []\n",
    "for entry in data:\n",
    "    for i, defn in enumerate(entry['definitions']):\n",
    "        for field in def_required:\n",
    "            if field not in defn:\n",
    "                def_missing.append((entry['entry_id'], i, field))\n",
    "\n",
    "if def_missing:\n",
    "    print(f\"WARNING: {len(def_missing)} definitions missing required fields\")\n",
    "    for entry_id, idx, field in def_missing[:10]:\n",
    "        print(f\"  {entry_id} def[{idx}] missing {field}\")\n",
    "else:\n",
    "    print(\"✓ All definitions have required fields\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f83ec04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported 10455 entries to berntsen_dictionary_processed.json\n",
      "Exported 50 sample entries to berntsen_dictionary_sample.json\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CELL 12: Export to JSON\n",
    "# ==============================================================================\n",
    "# This cell:\n",
    "# - Exports the processed data to a JSON file\n",
    "# - Ready for import into vector database\n",
    "\n",
    "import json\n",
    "\n",
    "output_filename = 'berntsen_dictionary_processed.json'\n",
    "\n",
    "with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Exported {len(data)} entries to {output_filename}\")\n",
    "\n",
    "# Also export a sample for inspection\n",
    "sample_filename = 'berntsen_dictionary_sample.json'\n",
    "sample_data = data[:50]  # First 50 entries\n",
    "\n",
    "with open(sample_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(sample_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Exported {len(sample_data)} sample entries to {sample_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ccf4bc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classification of All entries with devanagari script\n",
    "\n",
    "#| Category | Count (approx) | Action | `entry_type` | Needs `referenced_entry`? |\n",
    "#|----------|----------------|--------|--------------|---------------------------|\n",
    "#| **A. Cross-references** (\"See X\") | ~50 | Keep as-is, add relationship | `headword` | Yes: `relationship: 'cross_reference'` |\n",
    "#| **B. Collocations** (० patterns) | ~400 | Create NEW entries | `collocation` | No - uses `base_word` instead |\n",
    "#| **C. Grammatical forms** (perf. of, past tense of, etc.) | ~40 | Add referenced_entry | `headword` | Yes: `relationship: 'base_form'` |\n",
    "#| **D. Reduplication** (redupl. of) | ~20 | Add referenced_entry | `headword` | Yes: `relationship: 'reduplication_of'` |\n",
    "#| **E. Abbreviations** (abbrev. of) | ~15 | Add referenced_entry | `headword` | Yes: `relationship: 'abbreviation_of'` |\n",
    "#| **F. Variants** (var. of) | ~5 | Add referenced_entry | `headword` | Yes: `relationship: 'variant_of'` |\n",
    "#| **G. Self-contained definitions** (measurements, cultural terms, suffixes, intensifiers, etc.) | ~400+ | No structural change | `headword` | No - Devanagari is just part of definition text |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c51687e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9836 entries\n",
      "\n",
      "Processed 9836 entries\n",
      "\n",
      "Example entry (index 300):\n",
      "{\n",
      "  \"entry_id\": \"berntsen_अवलंबून_5\",\n",
      "  \"headword_devanagari\": \"अवलंबून\",\n",
      "  \"headword_romanized\": \"avalambūna\",\n",
      "  \"full_entry\": \"अवलंबून avalambūna , असणे asaṇē to be dependent on.\",\n",
      "  \"source_page\": 5\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#removes part_of_speech\n",
    "#adds entry_id\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from copy import deepcopy\n",
    "\n",
    "# Load the dictionary\n",
    "with open('berntsen_dictionary.json', 'r', encoding='utf-8') as f:\n",
    "    original_data = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(original_data)} entries\")\n",
    "\n",
    "# Create new data with proper field ordering\n",
    "data = []\n",
    "for entry in original_data:\n",
    "    # Create new ordered dictionary with entry_id first\n",
    "    new_entry = OrderedDict()\n",
    "    new_entry['entry_id'] = f\"berntsen_{entry['headword_devanagari']}_{entry['source_page']}\"\n",
    "    new_entry['headword_devanagari'] = entry['headword_devanagari']\n",
    "    new_entry['headword_romanized'] = entry['headword_romanized']\n",
    "    new_entry['full_entry'] = entry['full_entry']\n",
    "    new_entry['source_page'] = entry['source_page']\n",
    "    # Note: part_of_speech field is intentionally not included (removed)\n",
    "    \n",
    "    data.append(new_entry)\n",
    "\n",
    "# Verify the result\n",
    "print(f\"\\nProcessed {len(data)} entries\")\n",
    "print(\"\\nExample entry (index 300):\")\n",
    "print(json.dumps(data[300], ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a20484bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Berntsen Dictionary, how part of speech is represented\n",
    "# Pattern 1: Sequential POS sections (most common)\n",
    "#       form: headword romanized POS1 definition(s). POS2 definition(s).\n",
    "#       example: \"अति ati adv. too much. pref. extremely, too much, over-.\"\n",
    "#       description: Each POS gets its own definition section which is separated by periods\n",
    "# Pattern 2: Numbered definitions within same POS\n",
    "#       form: headword romanized POS 1. def1. 2. def2. 3. def3.\n",
    "#       example: \"अंक aṅka m. 1. number. 2. issue (of a magazine, newspaper). 3. act (of a play).\"\n",
    "#       description: Numbers belong to the SAME POS. All numbered definitions share the first POS mentioned\n",
    "# Pattern 3: Mixed - numbered defs THEN new POS\n",
    "#       form: headword romanized POS1 1. def1. 2. def2. POS2 def3.\n",
    "#       example: \"अखंड akhaṇḍa adj. inv. 1. entire, in one piece. 2. continuous. adv. continuously.\"\n",
    "#       explanation of example: Definitions 1 and 2 belong to adj. inv. \n",
    "#       When adv. appears, it starts a NEW section with its own definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc6b35fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries: 9836\n",
      "Entries with definitions: 9836 (100.0%)\n",
      "Entries without definitions: 0 (0.0%)\n",
      "Entries with null POS: 348 (3.5%)\n",
      "Total definitions parsed: 12167\n",
      "Average definitions per entry: 1.24\n",
      "\n",
      "================================================================================\n",
      "EXAMPLES OF ENTRIES WITH NULL POS:\n",
      "================================================================================\n",
      "\n",
      "अडीच: अडीच aḍīca two and one half.\n",
      "  POS: None, Definition: two and one half\n",
      "\n",
      "अदपाव: अदपाव adapāva one-eighth of a शेर or kilo.\n",
      "  POS: None, Definition: one-eighth of a शेर or kilo\n",
      "\n",
      "अलीकडे: अलीकडे alīkaḍē See अलिकडे .\n",
      "  POS: None, Definition: See अलिकडे\n",
      "\n",
      "अवलंबून: अवलंबून avalambūna , असणे asaṇē to be dependent on.\n",
      "  POS: None, Definition: असणे asaṇē to be dependent on\n",
      "\n",
      "असेना: असेना asēnā , का kā so what.\n",
      "  POS: None, Definition: का kā so what\n",
      "\n",
      "अहोजाहो: अहोजाहो ahōjāhō respectful address.\n",
      "  POS: None, Definition: respectful address\n",
      "\n",
      "आ: आ ā , करणे karaṇē to open one's mouth (to say `ah').\n",
      "  POS: None, Definition: करणे karaṇē to open one's mouth (to say `ah')\n",
      "\n",
      "आटपाट: आटपाट āṭapāṭa , नगर nagara a big town.\n",
      "  POS: None, Definition: नगर nagara a big town\n",
      "\n",
      "आटोपणे: आटोपणे āṭōpaṇē See आटपणे .\n",
      "  POS: None, Definition: See आटपणे\n",
      "\n",
      "आपापसात: आपापसात āpāpasāta among ... selves.\n",
      "  POS: None, Definition: among ... selves\n"
     ]
    }
   ],
   "source": [
    "#definitions[]\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "\n",
    "def parse_definitions(entry):\n",
    "    \"\"\"\n",
    "    Parse the full_entry to extract definitions with their POS and numbers.\n",
    "    \n",
    "    Args:\n",
    "        entry: Dictionary containing 'full_entry', 'headword_romanized'\n",
    "    \n",
    "    Returns:\n",
    "        List of definition dictionaries with 'definition', 'pos', 'number'\n",
    "    \"\"\"\n",
    "    full_entry = entry['full_entry']\n",
    "    romanized = entry['headword_romanized']\n",
    "    \n",
    "    # Step 1: Extract the definition part (everything after romanized headword)\n",
    "    parts = full_entry.split(romanized, 1)\n",
    "    if len(parts) <= 1:\n",
    "        # Edge case: romanized not found, return empty\n",
    "        return []\n",
    "    \n",
    "    definition_text = parts[1].strip()\n",
    "    \n",
    "    # If definition_text starts with comma, remove it\n",
    "    if definition_text.startswith(','):\n",
    "        definition_text = definition_text[1:].strip()\n",
    "    \n",
    "    # If there's no text at all, return empty\n",
    "    if not definition_text:\n",
    "        return []\n",
    "    \n",
    "    # Step 2: Define all possible POS markers (order matters - longest first to avoid partial matches)\n",
    "    # IMPORTANT: Include both \"v. t.\" and \"v.t.\" formats\n",
    "    pos_markers = [\n",
    "        'adj. inv.', 'adv. suff.', 'adj. suff. inv.', 'adj. suff.',\n",
    "        'n. suff.', 'n.suff.', 'm. suff.', 'f. suff.', \n",
    "        'v. t.', 'v. i.', 'v.i.', 'v.t.',  # Added both formats with and without space\n",
    "        'adj.', 'adv.', 'pref.', 'suff.',\n",
    "        'conj.', 'post.', 'pron.', 'interj.', 'poss.',\n",
    "        'f.(i)', 'f.(e)', 'm.(i)', 'm.(e)',\n",
    "        'n.', 'm.', 'f.'\n",
    "    ]\n",
    "    \n",
    "    # Step 3: Find all POS markers and their positions in the text\n",
    "    pos_locations = []\n",
    "    for pos in pos_markers:\n",
    "        # Find all occurrences of this POS marker\n",
    "        index = 0\n",
    "        while True:\n",
    "            index = definition_text.find(pos, index)\n",
    "            if index == -1:\n",
    "                break\n",
    "            # Check if this is at the start or preceded by space/period\n",
    "            if index == 0 or definition_text[index-1] in [' ', '.']:\n",
    "                # Check if followed by space or end of string\n",
    "                end_index = index + len(pos)\n",
    "                if end_index >= len(definition_text) or definition_text[end_index] == ' ':\n",
    "                    pos_locations.append({\n",
    "                        'pos': pos,\n",
    "                        'start': index,\n",
    "                        'end': end_index\n",
    "                    })\n",
    "            index += 1\n",
    "    \n",
    "    # Sort by position\n",
    "    pos_locations.sort(key=lambda x: x['start'])\n",
    "    \n",
    "    # Step 4: If no POS found, treat entire text as definition with null POS\n",
    "    if not pos_locations:\n",
    "        # Remove trailing period\n",
    "        cleaned_text = definition_text.strip()\n",
    "        if cleaned_text.endswith('.'):\n",
    "            cleaned_text = cleaned_text[:-1].strip()\n",
    "        \n",
    "        if cleaned_text:\n",
    "            return [{\n",
    "                'definition': cleaned_text,\n",
    "                'pos': None,\n",
    "                'number': None\n",
    "            }]\n",
    "        else:\n",
    "            return []\n",
    "    \n",
    "    # Step 5: Split text into sections by POS\n",
    "    definitions = []\n",
    "    \n",
    "    for i, pos_info in enumerate(pos_locations):\n",
    "        current_pos = pos_info['pos']\n",
    "        start = pos_info['end']\n",
    "        \n",
    "        # Find where this POS section ends (where next POS starts, or end of text)\n",
    "        if i + 1 < len(pos_locations):\n",
    "            end = pos_locations[i + 1]['start']\n",
    "        else:\n",
    "            end = len(definition_text)\n",
    "        \n",
    "        # Extract the definition text for this POS\n",
    "        section_text = definition_text[start:end].strip()\n",
    "        \n",
    "        # Step 6: Check if this section has numbered definitions (1., 2., 3., etc.)\n",
    "        numbered_pattern = r'(\\d+)\\.\\s*([^0-9]+?)(?=\\s*\\d+\\.|$)'\n",
    "        numbered_matches = list(re.finditer(numbered_pattern, section_text))\n",
    "        \n",
    "        if numbered_matches:\n",
    "            # Parse numbered definitions\n",
    "            for match in numbered_matches:\n",
    "                number = int(match.group(1))\n",
    "                def_text = match.group(2).strip()\n",
    "                \n",
    "                # Clean up: remove trailing period if present\n",
    "                if def_text.endswith('.'):\n",
    "                    def_text = def_text[:-1].strip()\n",
    "                \n",
    "                # Skip empty definitions\n",
    "                if def_text:\n",
    "                    definitions.append({\n",
    "                        'definition': def_text,\n",
    "                        'pos': current_pos,\n",
    "                        'number': number\n",
    "                    })\n",
    "        else:\n",
    "            # No numbers - this is a single unnumbered definition\n",
    "            # Clean the section text\n",
    "            section_text = section_text.strip()\n",
    "            \n",
    "            # Remove trailing period\n",
    "            if section_text.endswith('.'):\n",
    "                section_text = section_text[:-1].strip()\n",
    "            \n",
    "            # Skip empty definitions\n",
    "            if section_text:\n",
    "                definitions.append({\n",
    "                    'definition': section_text,\n",
    "                    'pos': current_pos,\n",
    "                    'number': None\n",
    "                })\n",
    "    \n",
    "    return definitions\n",
    "\n",
    "\n",
    "# Add definitions to all entries\n",
    "for entry in data:\n",
    "    entry['definitions'] = parse_definitions(entry)\n",
    "\n",
    "# Calculate metrics\n",
    "total_entries = len(data)\n",
    "entries_with_defs = sum(1 for entry in data if entry['definitions'])\n",
    "entries_without_defs = total_entries - entries_with_defs\n",
    "total_defs = sum(len(e['definitions']) for e in data)\n",
    "entries_with_null_pos = sum(1 for entry in data if entry['definitions'] and any(d['pos'] is None for d in entry['definitions']))\n",
    "\n",
    "print(f\"Total entries: {total_entries}\")\n",
    "print(f\"Entries with definitions: {entries_with_defs} ({entries_with_defs/total_entries*100:.1f}%)\")\n",
    "print(f\"Entries without definitions: {entries_without_defs} ({entries_without_defs/total_entries*100:.1f}%)\")\n",
    "print(f\"Entries with null POS: {entries_with_null_pos} ({entries_with_null_pos/total_entries*100:.1f}%)\")\n",
    "print(f\"Total definitions parsed: {total_defs}\")\n",
    "print(f\"Average definitions per entry: {total_defs/total_entries:.2f}\")\n",
    "\n",
    "# Show examples of entries with null POS\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXAMPLES OF ENTRIES WITH NULL POS:\")\n",
    "print(\"=\" * 80)\n",
    "null_pos_entries = [e for e in data if e['definitions'] and any(d['pos'] is None for d in e['definitions'])]\n",
    "for entry in null_pos_entries[:10]:\n",
    "    print(f\"\\n{entry['headword_devanagari']}: {entry['full_entry']}\")\n",
    "    for d in entry['definitions']:\n",
    "        print(f\"  POS: {d['pos']}, Definition: {d['definition']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8f81b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *1.headword_devanagari\n",
    "# *2.headword_romanized \n",
    "# *4.full_entry: everything within the div from the webpage, including devanagari, romanized, and the full text\n",
    "#   of the definition\n",
    "# *5.source_page\n",
    "# *6.entry_id: a unique id to represent this particular word; eg. berntsen_पाणी_5. The\n",
    "#   dictionaryname_headword_devanagari_pagenumber\n",
    "# 7.definition(array): an array of the definitions\n",
    "# 8.pos_normalized: e.g. noun.feminine; Use for metadata filtering in vector DB\n",
    "# 9.gender: ;Optional fine-grained filters\n",
    "# 10.declension_class: ;Optional fine-grained filters\n",
    "# 11.pos_display: the symbol for the part of speech like adj...; \n",
    "#    Include in content shown to LLM (keeps linguistic accuracy)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46111aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
